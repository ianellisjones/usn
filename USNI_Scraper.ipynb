{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOskFaUCKANg6AZvT6sKQiA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ianellisjones/usn/blob/main/USNI_Scraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmvNN1arwBIS",
        "outputId": "86eacb0a-3407-4f8b-e562-8f348a615655"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.83)] [Connected to cloud.r-pr\r                                                                               \rHit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:3 https://cli.github.com/packages stable InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:6 https://dl.google.com/linux/chrome/deb stable InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:8 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "fonts-liberation is already the newest version (1:1.07.4-11).\n",
            "libasound2 is already the newest version (1.2.6.1-1ubuntu1).\n",
            "libatk-bridge2.0-0 is already the newest version (2.38.0-3).\n",
            "lsb-release is already the newest version (11.1.0ubuntu4).\n",
            "libappindicator3-1 is already the newest version (12.10.1+20.10.20200706.1-0ubuntu1).\n",
            "ca-certificates is already the newest version (20240203~22.04.1).\n",
            "libnspr4 is already the newest version (2:4.35-0ubuntu0.22.04.1).\n",
            "libnss3 is already the newest version (2:3.98-0ubuntu0.22.04.2).\n",
            "unzip is already the newest version (6.0-26ubuntu3.2).\n",
            "wget is already the newest version (1.21.2-2ubuntu1.1).\n",
            "xdg-utils is already the newest version (1.1.3-4.1ubuntu3~22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 44 not upgraded.\n",
            "--2025-11-24 02:56:40--  https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
            "Resolving dl.google.com (dl.google.com)... 172.253.62.91, 172.253.62.190, 172.253.62.136, ...\n",
            "Connecting to dl.google.com (dl.google.com)|172.253.62.91|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 117885136 (112M) [application/x-debian-package]\n",
            "Saving to: ‘google-chrome-stable_current_amd64.deb.3’\n",
            "\n",
            "google-chrome-stabl 100%[===================>] 112.42M   470MB/s    in 0.2s    \n",
            "\n",
            "2025-11-24 02:56:40 (470 MB/s) - ‘google-chrome-stable_current_amd64.deb.3’ saved [117885136/117885136]\n",
            "\n",
            "(Reading database ... 122239 files and directories currently installed.)\n",
            "Preparing to unpack google-chrome-stable_current_amd64.deb ...\n",
            "Unpacking google-chrome-stable (142.0.7444.175-1) over (142.0.7444.175-1) ...\n",
            "Setting up google-chrome-stable (142.0.7444.175-1) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "0 upgraded, 0 newly installed, 0 to remove and 44 not upgraded.\n",
            "Requirement already satisfied: selenium in /usr/local/lib/python3.12/dist-packages (4.38.0)\n",
            "Requirement already satisfied: webdriver-manager in /usr/local/lib/python3.12/dist-packages (4.0.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.5)\n",
            "Requirement already satisfied: urllib3<3.0,>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (2.5.0)\n",
            "Requirement already satisfied: trio<1.0,>=0.31.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (0.32.0)\n",
            "Requirement already satisfied: trio-websocket<1.0,>=0.12.2 in /usr/local/lib/python3.12/dist-packages (from selenium) (0.12.2)\n",
            "Requirement already satisfied: certifi>=2025.10.5 in /usr/local/lib/python3.12/dist-packages (from selenium) (2025.11.12)\n",
            "Requirement already satisfied: typing_extensions<5.0,>=4.15.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (4.15.0)\n",
            "Requirement already satisfied: websocket-client<2.0,>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (1.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from webdriver-manager) (2.32.4)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from webdriver-manager) (1.2.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from webdriver-manager) (25.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.8)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium) (25.4.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium) (3.11)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium) (1.3.1)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.12/dist-packages (from trio-websocket<1.0,>=0.12.2->selenium) (1.3.2)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (1.7.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->webdriver-manager) (3.4.4)\n",
            "Requirement already satisfied: h11<1,>=0.16.0 in /usr/local/lib/python3.12/dist-packages (from wsproto>=0.14->trio-websocket<1.0,>=0.12.2->selenium) (0.16.0)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "%%shell\n",
        "# 1. Clean up old/broken installations\n",
        "sudo apt-get remove chromium-browser chromium-chromedriver -y > /dev/null 2>&1\n",
        "\n",
        "# 2. Install dependencies\n",
        "sudo apt-get update\n",
        "sudo apt-get install -y wget unzip ca-certificates fonts-liberation libappindicator3-1 libasound2 libatk-bridge2.0-0 libnspr4 libnss3 lsb-release xdg-utils\n",
        "\n",
        "# 3. Install Official Google Chrome (Stable)\n",
        "wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
        "sudo dpkg -i google-chrome-stable_current_amd64.deb\n",
        "sudo apt-get -f install -y  # Fix any missing deps\n",
        "\n",
        "# 4. Install Python libs\n",
        "pip install selenium webdriver-manager beautifulsoup4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install selenium-stealth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9z1F41Lw8wk",
        "outputId": "4373dc96-aed0-4612-cc90-9e2e2781dd51"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: selenium-stealth in /usr/local/lib/python3.12/dist-packages (1.0.6)\n",
            "Requirement already satisfied: selenium in /usr/local/lib/python3.12/dist-packages (from selenium-stealth) (4.38.0)\n",
            "Requirement already satisfied: urllib3<3.0,>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from urllib3[socks]<3.0,>=2.5.0->selenium->selenium-stealth) (2.5.0)\n",
            "Requirement already satisfied: trio<1.0,>=0.31.0 in /usr/local/lib/python3.12/dist-packages (from selenium->selenium-stealth) (0.32.0)\n",
            "Requirement already satisfied: trio-websocket<1.0,>=0.12.2 in /usr/local/lib/python3.12/dist-packages (from selenium->selenium-stealth) (0.12.2)\n",
            "Requirement already satisfied: certifi>=2025.10.5 in /usr/local/lib/python3.12/dist-packages (from selenium->selenium-stealth) (2025.11.12)\n",
            "Requirement already satisfied: typing_extensions<5.0,>=4.15.0 in /usr/local/lib/python3.12/dist-packages (from selenium->selenium-stealth) (4.15.0)\n",
            "Requirement already satisfied: websocket-client<2.0,>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from selenium->selenium-stealth) (1.9.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium->selenium-stealth) (25.4.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium->selenium-stealth) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium->selenium-stealth) (3.11)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium->selenium-stealth) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium->selenium-stealth) (1.3.1)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.12/dist-packages (from trio-websocket<1.0,>=0.12.2->selenium->selenium-stealth) (1.3.2)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from urllib3[socks]<3.0,>=2.5.0->selenium->selenium-stealth) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.16.0 in /usr/local/lib/python3.12/dist-packages (from wsproto>=0.14->trio-websocket<1.0,>=0.12.2->selenium->selenium-stealth) (0.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "US NAVY FLEET TRACKER - USNI NEWS MODULE (v6.1 - Bugfix)\n",
        "\n",
        "A specialized scraper that reads the \"USNI News Fleet and Marine Tracker\".\n",
        "Uses Selenium-Stealth to bypass Cloudflare.\n",
        "Uses Dictionary Matching to correctly identify locations.\n",
        "\n",
        "Fixes v6.1:\n",
        "- Fixed AttributeError by renaming 'header_triggers' to 'location_triggers'.\n",
        "\"\"\"\n",
        "\n",
        "import re\n",
        "import csv\n",
        "import sys\n",
        "import time\n",
        "import os\n",
        "from typing import List, Dict\n",
        "\n",
        "# External dependencies\n",
        "try:\n",
        "    from bs4 import BeautifulSoup\n",
        "    from selenium import webdriver\n",
        "    from selenium.webdriver.chrome.options import Options\n",
        "    from selenium.webdriver.chrome.service import Service\n",
        "    from webdriver_manager.chrome import ChromeDriverManager\n",
        "    from selenium_stealth import stealth\n",
        "except ImportError:\n",
        "    print(\"CRITICAL ERROR: Missing dependencies.\")\n",
        "    print(\"Please run: pip install selenium webdriver-manager selenium-stealth\")\n",
        "    sys.exit(1)\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "TARGET_URL = \"https://news.usni.org/2025/11/17/usni-news-fleet-and-marine-tracker-nov-17-2025\"\n",
        "OUTPUT_FILENAME = \"usni_fleet_status.csv\"\n",
        "\n",
        "# --- LOCATION DICTIONARY ---\n",
        "KNOWN_LOCATIONS = {\n",
        "    # Specific Ports\n",
        "    \"Sasebo\": [\"sasebo\"],\n",
        "    \"Yokosuka\": [\"yokosuka\"],\n",
        "    \"Okinawa\": [\"okinawa\"],\n",
        "    \"Busan\": [\"busan\"],\n",
        "    \"Guam\": [\"guam\", \"apra\"],\n",
        "    \"Pearl Harbor\": [\"pearl harbor\", \"hawaii\"],\n",
        "    \"San Diego\": [\"san diego\", \"north island\"],\n",
        "    \"Bremerton\": [\"bremerton\", \"kitsap\"],\n",
        "    \"Everett\": [\"everett\"],\n",
        "    \"Norfolk\": [\"norfolk\", \"portsmouth\", \"virginia beach\", \"little creek\"],\n",
        "    \"Mayport\": [\"mayport\"],\n",
        "    \"Rota\": [\"rota\", \"spain\"],\n",
        "    \"Bahrain\": [\"bahrain\", \"manama\"],\n",
        "    \"Souda Bay\": [\"souda bay\", \"crete\"],\n",
        "    \"Singapore\": [\"singapore\", \"changi\"],\n",
        "    \"Manila\": [\"manila\", \"subic\"],\n",
        "    \"Duqm\": [\"duqm\", \"oman\"],\n",
        "\n",
        "    # Regions / Seas\n",
        "    \"Philippine Sea\": [\"philippine sea\"],\n",
        "    \"South China Sea\": [\"south china sea\", \"spratly\", \"paracel\"],\n",
        "    \"Western Pacific\": [\"western pacific\", \"westpac\"],\n",
        "    \"Eastern Pacific\": [\"eastern pacific\"],\n",
        "    \"Atlantic Ocean\": [\"atlantic\"],\n",
        "    \"Mediterranean\": [\"mediterranean\", \"ionian\", \"adriatic\"],\n",
        "    \"Red Sea\": [\"red sea\", \"bab el-mandeb\"],\n",
        "    \"Persian Gulf\": [\"persian gulf\", \"arabian gulf\"],\n",
        "    \"Gulf of Oman\": [\"gulf of oman\"],\n",
        "    \"Caribbean Sea\": [\"caribbean\", \"st. croix\", \"virgin islands\"],\n",
        "    \"North Sea\": [\"north sea\"],\n",
        "    \"Norwegian Sea\": [\"norwegian sea\"]\n",
        "}\n",
        "\n",
        "class USNIParser:\n",
        "    \"\"\"Parses narrative news text into structured fleet data.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # Matches \"USS Name (Hull)\" or just \"USS Name\" if Hull is missing\n",
        "        # Captures: Group 1 = Name, Group 2 = Hull (Optional)\n",
        "        self.ship_pattern = re.compile(r\"USS\\s+([A-Z][a-z]+(?:\\s+[A-Z][a-z]+)*)(?:\\s+\\(([A-Z]{2,4}-\\d+)\\))?\")\n",
        "\n",
        "        # Triggers for Section Headers\n",
        "        # FIXED: Renamed from header_triggers to match usage below\n",
        "        self.location_triggers = [\"In the\", \"In \", \"Off the coast\", \"Carrier Strike Group\", \"Amphibious Ready Group\"]\n",
        "\n",
        "    def clean_text(self, text: str) -> str:\n",
        "        return \" \".join(text.split()).strip()\n",
        "\n",
        "    def identify_location_in_text(self, text: str) -> str:\n",
        "        \"\"\"Scans text for known locations from the dictionary.\"\"\"\n",
        "        text_lower = text.lower()\n",
        "        best_match = None\n",
        "        best_index = -1\n",
        "\n",
        "        for loc_label, keywords in KNOWN_LOCATIONS.items():\n",
        "            for k in keywords:\n",
        "                index = text_lower.rfind(k)\n",
        "                if index > best_index:\n",
        "                    best_index = index\n",
        "                    best_match = loc_label\n",
        "\n",
        "        return best_match\n",
        "\n",
        "    def extract_ships_from_section(self, location_context: str, text_block: str) -> List[Dict]:\n",
        "        ships_found = []\n",
        "\n",
        "        # Find all ships in the paragraph\n",
        "        for match in self.ship_pattern.finditer(text_block):\n",
        "            ship_name = match.group(1)\n",
        "            hull = match.group(2) if match.group(2) else \"Unknown\"\n",
        "\n",
        "            # Get the specific sentence\n",
        "            sentence = self.get_surrounding_sentence(text_block, match.start())\n",
        "\n",
        "            # STRATEGY:\n",
        "            # 1. Look for a specific location in the sentence (e.g. \"arrived in Sasebo\")\n",
        "            # 2. If none, use the Section Header (e.g. \"In Japan\")\n",
        "\n",
        "            specific_loc = self.identify_location_in_text(sentence)\n",
        "\n",
        "            if specific_loc:\n",
        "                final_loc = specific_loc\n",
        "            else:\n",
        "                # Clean up the header context (remove \"In \", \"In the \")\n",
        "                final_loc = re.sub(r'^(In the |In )', '', location_context).strip()\n",
        "\n",
        "            # Final fallback for \"Global\"\n",
        "            if final_loc in [\"Unspecified / Global\", \"Japan\"]:\n",
        "                if \"sasebo\" in sentence.lower(): final_loc = \"Sasebo\"\n",
        "                if \"yokosuka\" in sentence.lower(): final_loc = \"Yokosuka\"\n",
        "\n",
        "            ships_found.append({\n",
        "                \"Hull\": hull,\n",
        "                \"Ship\": f\"USS {ship_name}\",\n",
        "                \"Location\": final_loc,\n",
        "                \"Status Sentence\": sentence\n",
        "            })\n",
        "        return ships_found\n",
        "\n",
        "    def get_surrounding_sentence(self, text: str, match_index: int) -> str:\n",
        "        # Find start of sentence\n",
        "        start = text.rfind('.', 0, match_index) + 1\n",
        "        # Find end of sentence\n",
        "        end = text.find('.', match_index)\n",
        "        if end == -1: end = len(text)\n",
        "        return text[start:end].strip()\n",
        "\n",
        "def fetch_with_selenium(url: str) -> str:\n",
        "    \"\"\"Launches Headless Chrome with Stealth extensions.\"\"\"\n",
        "    print(\"[*] Launching Google Chrome (Stealth Mode)...\")\n",
        "\n",
        "    chrome_options = Options()\n",
        "    chrome_options.add_argument(\"--headless\")\n",
        "    chrome_options.add_argument(\"--no-sandbox\")\n",
        "    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
        "    chrome_options.add_argument(\"--window-size=1920,1080\")\n",
        "    chrome_options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
        "    chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
        "    chrome_options.add_experimental_option('useAutomationExtension', False)\n",
        "\n",
        "    try:\n",
        "        service = Service(ChromeDriverManager().install())\n",
        "        driver = webdriver.Chrome(service=service, options=chrome_options)\n",
        "\n",
        "        stealth(driver,\n",
        "            languages=[\"en-US\", \"en\"],\n",
        "            vendor=\"Google Inc.\",\n",
        "            platform=\"Win32\",\n",
        "            webgl_vendor=\"Intel Inc.\",\n",
        "            renderer=\"Intel Iris OpenGL Engine\",\n",
        "            fix_hairline=True,\n",
        "        )\n",
        "\n",
        "        print(f\"[*] Navigating to: {url}\")\n",
        "        driver.get(url)\n",
        "\n",
        "        print(\"    > Waiting for Cloudflare check...\")\n",
        "        time.sleep(8) # Wait for redirect\n",
        "\n",
        "        # Check title to see if we passed\n",
        "        if \"Just a moment\" in driver.title:\n",
        "            print(\"[!] Still seeing Cloudflare page. Waiting longer...\")\n",
        "            time.sleep(10)\n",
        "\n",
        "        page_source = driver.page_source\n",
        "        return page_source\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[!] Selenium Error: {e}\")\n",
        "        return None\n",
        "    finally:\n",
        "        if 'driver' in locals():\n",
        "            driver.quit()\n",
        "\n",
        "def parse_article(html_content) -> List[Dict]:\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "    parser = USNIParser()\n",
        "    fleet_data = []\n",
        "    current_location_context = \"Unspecified / Global\"\n",
        "\n",
        "    # Debug\n",
        "    title = soup.title.string if soup.title else \"No Title\"\n",
        "    print(f\"    > Page Title: {title}\")\n",
        "\n",
        "    article_body = soup.find('div', class_='entry-content')\n",
        "    if not article_body: article_body = soup.body\n",
        "\n",
        "    if article_body:\n",
        "        # USNI uses <strong> tags inside <p> tags for location headers\n",
        "        # or plain 3/4 tags. We scan everything.\n",
        "        all_elements = article_body.find_all(['p', 'h3', 'h4', 'strong'])\n",
        "\n",
        "        for element in all_elements:\n",
        "            text = parser.clean_text(element.get_text())\n",
        "            if not text: continue\n",
        "\n",
        "            # Check if this element is a LOCATION HEADER\n",
        "            if any(text.startswith(t) for t in parser.location_triggers) and len(text) < 60:\n",
        "                current_location_context = text\n",
        "                continue\n",
        "\n",
        "            # Extract ships using current context\n",
        "            ships = parser.extract_ships_from_section(current_location_context, text)\n",
        "            if ships: fleet_data.extend(ships)\n",
        "\n",
        "    return fleet_data\n",
        "\n",
        "def main():\n",
        "    print(f\"{'='*90}\")\n",
        "    print(f\"USNI NEWS FLEET TRACKER (STEALTH ENGINE v6.1)\")\n",
        "    print(f\"{'='*90}\\n\")\n",
        "\n",
        "    html = fetch_with_selenium(TARGET_URL)\n",
        "    if not html:\n",
        "        return\n",
        "\n",
        "    fleet_list = parse_article(html)\n",
        "\n",
        "    if not fleet_list:\n",
        "        print(\"[!] No ships found.\")\n",
        "        return\n",
        "\n",
        "    # Deduplication logic\n",
        "    unique_fleet = {}\n",
        "    for ship in fleet_list:\n",
        "        # Keep the entry with the most descriptive location (not \"Unspecified\")\n",
        "        if ship['Hull'] not in unique_fleet:\n",
        "            unique_fleet[ship['Hull']] = ship\n",
        "        else:\n",
        "            current = unique_fleet[ship['Hull']]\n",
        "            # If current is unspecified but new one is specific, update it\n",
        "            if current['Location'] in [\"Unspecified / Global\", \"Japan\"] and ship['Location'] not in [\"Unspecified / Global\", \"Japan\"]:\n",
        "                unique_fleet[ship['Hull']] = ship\n",
        "\n",
        "    final_list = list(unique_fleet.values())\n",
        "\n",
        "    print(f\"[*] Extraction Complete. Found {len(final_list)} unique ships.\")\n",
        "\n",
        "    print(f\"\\n{'HULL':<10} | {'LOCATION':<25} | {'STATUS SNIPPET'}\")\n",
        "    print(f\"{'-'*10}-+-{'-'*25}-+-{'-'*50}\")\n",
        "\n",
        "    for ship in final_list:\n",
        "        # Clean snippet for display\n",
        "        snippet = (ship['Status Sentence'][:75] + '..') if len(ship['Status Sentence']) > 75 else ship['Status Sentence']\n",
        "        print(f\"{ship['Hull']:<10} | {ship['Location']:<25} | {snippet}\")\n",
        "\n",
        "    try:\n",
        "        with open(OUTPUT_FILENAME, 'w', newline='', encoding='utf-8') as f:\n",
        "            fieldnames = [\"Hull\", \"Ship\", \"Location\", \"Status Sentence\"]\n",
        "            writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
        "            writer.writeheader()\n",
        "            writer.writerows(final_list)\n",
        "        print(f\"\\n[+] Report saved to '{OUTPUT_FILENAME}'\")\n",
        "    except PermissionError:\n",
        "        print(f\"\\n[!] ERROR: Could not write to CSV. Is the file open?\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhYIS2Yryo-D",
        "outputId": "ac1816f3-bac7-48cb-d587-67b07ea5a3a2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==========================================================================================\n",
            "USNI NEWS FLEET TRACKER (STEALTH ENGINE v6.1)\n",
            "==========================================================================================\n",
            "\n",
            "[*] Launching Google Chrome (Stealth Mode)...\n",
            "[*] Navigating to: https://news.usni.org/2025/11/17/usni-news-fleet-and-marine-tracker-nov-17-2025\n",
            "    > Waiting for Cloudflare check...\n",
            "    > Page Title: USNI News Fleet and Marine Tracker: Nov. 17, 2025 - USNI News\n",
            "[*] Extraction Complete. Found 19 unique ships.\n",
            "\n",
            "HULL       | LOCATION                  | STATUS SNIPPET\n",
            "-----------+---------------------------+---------------------------------------------------\n",
            "LHA-7      | Sasebo                    | Amphibious warship USS Tripoli (LHA-7) is in port in Sasebo, Japan\n",
            "LSD-47     | Okinawa                   | Tripoli will operate with Amphibious Squadron 11 ships USS Rushmore (LSD-47..\n",
            "LPD-18     | Okinawa                   | Tripoli will operate with Amphibious Squadron 11 ships USS Rushmore (LSD-47..\n",
            "LPD-22     | Okinawa                   | Tripoli will operate with Amphibious Squadron 11 ships USS Rushmore (LSD-47..\n",
            "CVN-73     | Philippine Sea            | Aircraft carrier USS George Washington (CVN-73) is underway in the Philippi..\n",
            "CVN-68     | South China Sea           | Aircraft carrier USS Nimitz (CVN-68) is underway in the South China Sea\n",
            "LHD-7      | Carrier Strike Group 11   | The Amphibious Ready Group includes USS Iwo Jima (LHD-7), USS Fort Lauderda..\n",
            "LPD-28     | Carrier Strike Group 11   | The Amphibious Ready Group includes USS Iwo Jima (LHD-7), USS Fort Lauderda..\n",
            "LPD-17     | Carrier Strike Group 11   | The Amphibious Ready Group includes USS Iwo Jima (LHD-7), USS Fort Lauderda..\n",
            "CG-70      | Caribbean Sea             | Guided-missile cruisers USS Lake Erie (CG-70) and USS Gettysburg (CG-64) ar..\n",
            "CG-64      | Caribbean Sea             | Guided-missile cruisers USS Lake Erie (CG-70) and USS Gettysburg (CG-64) ar..\n",
            "Unknown    | Carrier Strike Group 11   | Aircraft carrier USS Gerald R\n",
            "LCS-30     | Carrier Strike Group 12   | Littoral Combat Ships USS Canberra (LCS-30), USS Santa Barbara (LCS-32) and..\n",
            "LCS-32     | Carrier Strike Group 12   | Littoral Combat Ships USS Canberra (LCS-30), USS Santa Barbara (LCS-32) and..\n",
            "LCS-16     | Carrier Strike Group 12   | Littoral Combat Ships USS Canberra (LCS-30), USS Santa Barbara (LCS-32) and..\n",
            "LHD-3      | Norfolk                   | Amphibious assault ship USS Kearsarge (LHD-3) departed Friday from Norfolk,..\n",
            "CVN-71     | San Diego                 | Aircraft carrier USS Theodore Roosevelt (CVN-71) departed Monday from San D..\n",
            "LHD-4      | San Diego                 | Amphibious assault ship USS Boxer (LHD-4) returned Wednesday to San Diego, ..\n",
            "LHD-8      | San Diego                 | Amphibious assault ship USS Makin Island (LHD-8) departed last Monday from ..\n",
            "\n",
            "[+] Report saved to 'usni_fleet_status.csv'\n"
          ]
        }
      ]
    }
  ]
}