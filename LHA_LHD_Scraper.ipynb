{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ianellisjones/usn/blob/main/LHA_LHD_Scraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "US Navy Amphibious Fleet Scraper (LHA/LHD)\n",
        "\n",
        "A utility to scrape deployment history from uscarriers.net and determine the\n",
        "latest physical location and status of US Navy Amphibious Assault Ships.\n",
        "\n",
        "Bypasses standard browser truncation by fetching raw HTML and parsing\n",
        "bottom-up context to handle verbose historical logs.\n",
        "\"\"\"\n",
        "\n",
        "import csv\n",
        "import re\n",
        "import sys\n",
        "from pathlib import Path\n",
        "from typing import List, Tuple, Dict, Optional\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Configuration\n",
        "SHIP_URLS: List[str] = [\n",
        "    \"http://uscarriers.net/lhd1history.htm\", # USS Wasp\n",
        "    \"http://uscarriers.net/lhd3history.htm\", # USS Kearsarge\n",
        "    \"http://uscarriers.net/lhd5history.htm\", # USS Bataan\n",
        "    \"http://uscarriers.net/lhd7history.htm\", # USS Iwo Jima\n",
        "    \"http://uscarriers.net/lhd2history.htm\", # USS Essex\n",
        "    \"http://uscarriers.net/lhd4history.htm\", # USS Boxer\n",
        "    \"http://uscarriers.net/lhd8history.htm\", # USS Makin Island\n",
        "    \"http://uscarriers.net/lha7history.htm\", # USS Tripoli\n",
        "    \"http://uscarriers.net/lha6history.htm\", # USS America\n",
        "]\n",
        "\n",
        "OUTPUT_FILENAME = \"amphib_status.csv\"\n",
        "USER_AGENT = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "\n",
        "def fetch_history_text(url: str, char_limit: int = 50000) -> str:\n",
        "    \"\"\"\n",
        "    Fetches the raw HTML content, strips tags, and returns the tail of the text.\n",
        "\n",
        "    Args:\n",
        "        url: The URL to scrape.\n",
        "        char_limit: Number of characters to retrieve from the end of the file.\n",
        "\n",
        "    Returns:\n",
        "        Cleaned text string from the bottom of the page.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = requests.get(url, headers={'User-Agent': USER_AGENT}, timeout=20)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "        full_text = soup.get_text(separator='\\n')\n",
        "\n",
        "        # Normalize whitespace\n",
        "        lines = [line.strip() for line in full_text.split('\\n') if line.strip()]\n",
        "        clean_text = '\\n'.join(lines)\n",
        "\n",
        "        return clean_text[-char_limit:] if len(clean_text) > char_limit else clean_text\n",
        "\n",
        "    except requests.RequestException as e:\n",
        "        return f\"ERROR: {str(e)}\"\n",
        "\n",
        "\n",
        "def parse_status_entry(text_block: str) -> Tuple[str, str]:\n",
        "    \"\"\"\n",
        "    Parses the text block to identify the most recent status entry based on\n",
        "    year context and naval movement keywords.\n",
        "    \"\"\"\n",
        "    lines = text_block.split('\\n')\n",
        "\n",
        "    # Contextual year tracking\n",
        "    current_year = \"Unknown\"\n",
        "    years_found = re.findall(r'(202[3-6])', text_block)\n",
        "\n",
        "    if years_found:\n",
        "        # Prioritize current operational years over future projection dates\n",
        "        priority_years = [y for y in years_found if y in ['2024', '2025']]\n",
        "        current_year = priority_years[-1] if priority_years else years_found[-1]\n",
        "\n",
        "    processed_lines = []\n",
        "    running_year = current_year\n",
        "\n",
        "    for line in lines:\n",
        "        # Update context if line starts with a relevant year\n",
        "        year_match = re.search(r'^202[3-6]', line)\n",
        "        if year_match:\n",
        "            running_year = year_match.group(0)\n",
        "\n",
        "        processed_lines.append({'text': line, 'year': running_year})\n",
        "\n",
        "    # Naval movement keywords\n",
        "    keywords = [\n",
        "        \"moored\", \"anchored\", \"underway\", \"arrived\", \"departed\",\n",
        "        \"transited\", \"operations\", \"returned\", \"participated\", \"conducted\",\n",
        "        \"moved to\", \"visited\", \"pulled into\", \"sea trials\", \"flight deck certification\"\n",
        "    ]\n",
        "\n",
        "    allowed_years = [\"2024\", \"2025\", \"2026\"]\n",
        "\n",
        "    # Bottom-up search for latest valid entry\n",
        "    for entry in reversed(processed_lines):\n",
        "        text_lower = entry['text'].lower()\n",
        "        year = entry['year']\n",
        "\n",
        "        if year in allowed_years and any(k in text_lower for k in keywords):\n",
        "            # Exclude summary ranges (e.g. \"From Jan - Mar\")\n",
        "            if text_lower.strip().startswith(\"from \") and \" - \" in text_lower:\n",
        "                continue\n",
        "            return year, entry['text']\n",
        "\n",
        "    return current_year, \"No status found.\"\n",
        "\n",
        "\n",
        "def categorize_location(text: str) -> str:\n",
        "    \"\"\"Derives a high-level location tag from the detailed status text.\"\"\"\n",
        "    text = text.lower()\n",
        "\n",
        "    location_map = {\n",
        "        # Ports\n",
        "        \"Norfolk / Portsmouth\": [\"norfolk\", \"portsmouth\", \"virginia beach\", \"nassco\"],\n",
        "        \"San Diego\": [\"san diego\", \"north island\", \"camp pendleton\"],\n",
        "        \"Bremerton / Kitsap\": [\"bremerton\", \"kitsap\"],\n",
        "        \"Newport News\": [\"newport news\"],\n",
        "        \"Yokosuka\": [\"yokosuka\"],\n",
        "        \"Pearl Harbor\": [\"pearl harbor\"],\n",
        "        \"Mayport\": [\"mayport\"],\n",
        "        \"Everett\": [\"everett\"],\n",
        "        \"Singapore\": [\"singapore\", \"changi\"],\n",
        "        \"Bahrain\": [\"bahrain\", \"manama\"],\n",
        "        \"Dubai\": [\"dubai\", \"jebel ali\"],\n",
        "        \"Busan\": [\"busan\"],\n",
        "        \"Guam\": [\"guam\", \"apra\"],\n",
        "        \"Sasebo\": [\"sasebo\", \"juliet basin\"],\n",
        "        \"Malaysia\": [\"malaysia\", \"klang\"],\n",
        "        \"Philippines\": [\"philippines\", \"manila\", \"subic\"],\n",
        "        \"Pascagoula\": [\"pascagoula\"],\n",
        "        # Regions\n",
        "        \"South China Sea\": [\"south china sea\"],\n",
        "        \"Philippine Sea\": [\"philippine sea\", \"okinawa\"],\n",
        "        \"Red Sea\": [\"red sea\"],\n",
        "        \"Persian Gulf\": [\"persian gulf\", \"arabian gulf\"],\n",
        "        \"Mediterranean\": [\"mediterranean\"],\n",
        "        \"Caribbean\": [\"caribbean\", \"st. croix\", \"trinidad\", \"tobago\"],\n",
        "        \"North Sea\": [\"north sea\"],\n",
        "        \"Atlantic Ocean\": [\"atlantic\"],\n",
        "        \"Pacific Ocean\": [\"pacific\"],\n",
        "        \"Indian Ocean\": [\"indian ocean\"],\n",
        "    }\n",
        "\n",
        "    for label, keywords in location_map.items():\n",
        "        if any(k in text for k in keywords):\n",
        "            return label\n",
        "\n",
        "    return \"Underway / Unknown\"\n",
        "\n",
        "\n",
        "def extract_date(text: str) -> str:\n",
        "    \"\"\"Extracts the last specific date (Month Day) mentioned in the text.\"\"\"\n",
        "    pattern = r'(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]*\\.?\\s+\\d{1,2}'\n",
        "    matches = re.findall(pattern, text, re.IGNORECASE)\n",
        "    return matches[-1] if matches else \"Date Unspecified\"\n",
        "\n",
        "\n",
        "def main():\n",
        "    print(f\"{'='*90}\")\n",
        "    print(f\"US NAVY AMPHIBIOUS FLEET - LATEST LOCATION TRACKER\")\n",
        "    print(f\"{'='*90}\\n\")\n",
        "\n",
        "    results: List[Dict[str, str]] = []\n",
        "\n",
        "    for url in SHIP_URLS:\n",
        "        # Extract hull number from URL (Matches LHD or LHA)\n",
        "        hull_match = re.search(r'(lh[ad]\\d+)', url)\n",
        "        hull = hull_match.group(1).upper() if hull_match else \"UNK\"\n",
        "\n",
        "        raw_text = fetch_history_text(url)\n",
        "\n",
        "        if \"ERROR\" in raw_text:\n",
        "            year, status, loc_tag, date_str = \"Error\", raw_text, \"Error\", \"Error\"\n",
        "        else:\n",
        "            year, status = parse_status_entry(raw_text)\n",
        "            loc_tag = categorize_location(status)\n",
        "            date_str = extract_date(status)\n",
        "\n",
        "            # Use Year as fallback if date is unspecified\n",
        "            if date_str == \"Date Unspecified\":\n",
        "                date_str = year\n",
        "\n",
        "        results.append({\n",
        "            \"Hull\": hull,\n",
        "            \"Location\": loc_tag,\n",
        "            \"Date\": date_str,\n",
        "            \"Status Sentence\": status,\n",
        "            \"Source URL\": url\n",
        "        })\n",
        "\n",
        "        # Console Output\n",
        "        print(f\"[{hull}] [{loc_tag}] [{date_str}] {status}\")\n",
        "\n",
        "    # Write to CSV\n",
        "    try:\n",
        "        output_path = Path(OUTPUT_FILENAME)\n",
        "        with output_path.open(mode='w', newline='', encoding='utf-8') as csvfile:\n",
        "            fieldnames = [\"Hull\", \"Location\", \"Date\", \"Status Sentence\", \"Source URL\"]\n",
        "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "            writer.writeheader()\n",
        "            writer.writerows(results)\n",
        "\n",
        "        print(f\"\\n{'='*90}\")\n",
        "        print(f\"SUCCESS: Report saved to '{output_path.absolute()}'\")\n",
        "        print(f\"{'='*90}\")\n",
        "\n",
        "    except PermissionError:\n",
        "        print(f\"\\nERROR: Could not write to {OUTPUT_FILENAME}. Is the file open?\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==========================================================================================\n",
            "US NAVY AMPHIBIOUS FLEET - LATEST LOCATION TRACKER\n",
            "==========================================================================================\n",
            "\n",
            "[LHD1] [Norfolk / Portsmouth] [May 19] April 14, USS Wasp moored at Berth 6, Pier 11 on Naval Station Norfolk after a 10-day underway for deck landing qualifications, in the Virginia Capes Op. Area; Underway again on April 28; Moored at Berth 6, Pier 6 on May 9; Moved \"dead-stick\" to Pier 1 in BAE Systems shipyard on May 19.\n",
            "[LHD3] [Norfolk / Portsmouth] [Nov. 14] September 26, USS Kearsarge moved from Pier 12 to Berth 3, Pier 14 on Naval Station Norfolk; Moved  to Berth 4, Pier 14 on Sept. 28; Underway again on Oct. 8; Moored at Berth 1, Pier 12 on Oct. 10; Underway in the Virginia Capes Op Area from Oct. 16-22 and Nov. 14-21.\n",
            "[LHD5] [Norfolk / Portsmouth] [2025] July ?, 2025 USS Bataan undocked and moored at  Berth 2E on NASSCO shipyard.\n",
            "[LHD7] [Caribbean] [Nov. 18] November 6, The Iwo Jima moored at Ann E. Abramson Marine Facility in Frederiksted,  St. Croix, U.S. Virgin Islands, for a four-day port call; Conducted a replenishment-at-sea with the USNS Kanawha (T-AO 196) on Nov. 14; Conducted operations approx. 40 n.m. northwest  of Trinidad and Tobago from Nov. 18-21.\n",
            "[LHD2] [San Diego] [Oct. 9] October 6, USS Essex departed Naval Base San Diego for sea trials following an extended 37-month availability; Anchored at A-173 for a brief stop before moored at Berth 5, Pier 2 on Oct. 9.\n",
            "[LHD4] [San Diego] [Nov. 12] November 4, USS Boxer moored at Berth 6, Pier 13 on Naval Base San Diego for a brief stop; Returned home on Nov. 12.\n",
            "[LHD8] [San Diego] [Nov. 10] October 18, USS Makin Island participated in Amphibious Capabilities Demonstration, in conjunction with the Marine Corps 250th birthday, off the coast of Camp Pendleton; Moored at Berth 5, Pier 8 on Oct. 21; Underway again from Nov. 10-13.\n",
            "[LHA7] [Sasebo] [Oct. 29] October 24, The Tripoli moored at Navy Pier East on White Beach Naval Facility in Okinawa for a two-day port call; Transited the Osumi Strait westbound on Oct. 28; Moored at Berth 3, Juliet Basin Wharf on Oct. 29.\n",
            "[LHA6] [San Diego] [2025] , USS America moored at Berth 5, Pier 13 in its new homeport of Naval Base San Diego after forward-deployed to Japan for nearly six years.\n",
            "\n",
            "==========================================================================================\n",
            "SUCCESS: Report saved to '/content/amphib_status.csv'\n",
            "==========================================================================================\n"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhazX4V2Z8CG",
        "outputId": "57dc24c0-c781-4067-b27c-c6a4e08b4451"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}