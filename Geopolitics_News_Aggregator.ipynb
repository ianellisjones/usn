{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<a href=\"https://colab.research.google.com/github/ianellisjones/usn/blob/main/Geopolitics_News_Aggregator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n\n# IEJ Intel Brief - News Aggregator\n\n**Drudge-Style AI-Powered Geopolitics Intelligence**\n\nDense, single-page news aggregation focused on geopolitics, defense, and global security.\n\n### Layout (3x3 Grid)\n```\n+---------+---------+---------+\n|  GLOBE  |   US    | EUROPE  |\n+---------+---------+---------+\n|  ASIA   |   IEJ   | MIDEAST |\n+---------+---------+---------+\n|CONFLICTS| CYBER   | FINANCE |\n+---------+---------+---------+\n```\n\n### Sections\n- **Globe**: International diplomacy, global institutions\n- **US**: Pentagon, Washington, domestic policy  \n- **Europe**: NATO, EU, UK, Russia, Ukraine\n- **Asia**: China, Taiwan, Japan, Korea, Indo-Pacific\n- **Middle East**: Israel, Iran, Gaza, Yemen, Syria\n- **Conflicts**: Active warfare, strikes, combat\n- **Cybersecurity**: Cyber attacks, hacking, digital warfare\n- **Finance**: Defense contracts, sanctions, arms deals\n\n---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Step 1: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%shell\n",
    "# Install required packages\n",
    "pip install feedparser anthropic requests beautifulsoup4 newspaper3k lxml_html_clean python-dateutil pytz --quiet\n",
    "\n",
    "# For GitHub deployment\n",
    "pip install PyGithub --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîë Step 2: Configuration\n",
    "\n",
    "Set your API keys and preferences here. You can store these in Colab secrets for security."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\nfrom datetime import datetime\nimport pytz\n\n# =============================================================================\n# CONFIGURATION - Edit these values\n# =============================================================================\n\n# Option 1: Use Colab secrets (recommended)\ntry:\n    from google.colab import userdata\n    ANTHROPIC_API_KEY = userdata.get('ANTHROPIC_API_KEY')\n    GITHUB_TOKEN = userdata.get('GITHUB_TOKEN')  # Optional: for auto-deploy\nexcept:\n    # Option 2: Set directly (not recommended for production)\n    ANTHROPIC_API_KEY = \"your-anthropic-api-key-here\"\n    GITHUB_TOKEN = None  # Optional\n\n# Site Configuration\nSITE_TITLE = \"IEJ\"\nSITE_SUBTITLE = \"Global Intelligence Briefing\"\nTIMEZONE = \"US/Eastern\"\n\n# GitHub Pages Configuration (optional)\nGITHUB_REPO = \"ianellisjones/usn\"  # Format: username/repo\nGITHUB_BRANCH = \"gh-pages\"\nOUTPUT_FILENAME = \"index.html\"\n\n# Layout Settings - Dense like Drudge\nHEADLINES_PER_SECTION = 8  # 6 sections x 8 = ~48 headlines\nTOTAL_HEADLINE_TARGET = 50\n\nprint(f\"Configuration loaded\")\nprint(f\"   Site: {SITE_TITLE}\")\nprint(f\"   Timezone: {TIMEZONE}\")\nprint(f\"   API Key: {'Set' if ANTHROPIC_API_KEY and ANTHROPIC_API_KEY != 'your-anthropic-api-key-here' else 'NOT SET'}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì∞ Step 3: News Sources Database\n",
    "\n",
    "Curated list of premium geopolitics and defense news sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# NEWS SOURCES - Organized by category\n",
    "# =============================================================================\n",
    "\n",
    "NEWS_SOURCES = {\n",
    "    # === DEFENSE & MILITARY ===\n",
    "    \"defense\": [\n",
    "        {\"name\": \"Defense News\", \"url\": \"https://www.defensenews.com/arc/outboundfeeds/rss/?outputType=xml\", \"type\": \"rss\"},\n",
    "        {\"name\": \"Breaking Defense\", \"url\": \"https://breakingdefense.com/feed/\", \"type\": \"rss\"},\n",
    "        {\"name\": \"Defense One\", \"url\": \"https://www.defenseone.com/rss/all/\", \"type\": \"rss\"},\n",
    "        {\"name\": \"Military Times\", \"url\": \"https://www.militarytimes.com/arc/outboundfeeds/rss/?outputType=xml\", \"type\": \"rss\"},\n",
    "        {\"name\": \"USNI News\", \"url\": \"https://news.usni.org/feed\", \"type\": \"rss\"},\n",
    "        {\"name\": \"War on the Rocks\", \"url\": \"https://warontherocks.com/feed/\", \"type\": \"rss\"},\n",
    "        {\"name\": \"The War Zone\", \"url\": \"https://www.thedrive.com/the-war-zone/feed\", \"type\": \"rss\"},\n",
    "        {\"name\": \"Naval News\", \"url\": \"https://www.navalnews.com/feed/\", \"type\": \"rss\"},\n",
    "        {\"name\": \"Air & Space Forces\", \"url\": \"https://www.airandspaceforces.com/feed/\", \"type\": \"rss\"},\n",
    "        {\"name\": \"Stars and Stripes\", \"url\": \"https://www.stripes.com/rss\", \"type\": \"rss\"},\n",
    "        {\"name\": \"Janes\", \"url\": \"https://www.janes.com/feeds/news\", \"type\": \"rss\"},\n",
    "    ],\n",
    "\n",
    "    # === GEOPOLITICS & FOREIGN POLICY ===\n",
    "    \"geopolitics\": [\n",
    "        {\"name\": \"Foreign Affairs\", \"url\": \"https://www.foreignaffairs.com/rss.xml\", \"type\": \"rss\"},\n",
    "        {\"name\": \"Foreign Policy\", \"url\": \"https://foreignpolicy.com/feed/\", \"type\": \"rss\"},\n",
    "        {\"name\": \"The Diplomat\", \"url\": \"https://thediplomat.com/feed/\", \"type\": \"rss\"},\n",
    "        {\"name\": \"CSIS\", \"url\": \"https://www.csis.org/analysis/feed\", \"type\": \"rss\"},\n",
    "        {\"name\": \"Brookings\", \"url\": \"https://www.brookings.edu/feed/\", \"type\": \"rss\"},\n",
    "        {\"name\": \"RAND\", \"url\": \"https://www.rand.org/news/press.xml\", \"type\": \"rss\"},\n",
    "        {\"name\": \"Carnegie Endowment\", \"url\": \"https://carnegieendowment.org/rss/solr/?fa=feeds\", \"type\": \"rss\"},\n",
    "        {\"name\": \"Council on Foreign Relations\", \"url\": \"https://www.cfr.org/rss/expert-brief\", \"type\": \"rss\"},\n",
    "        {\"name\": \"Atlantic Council\", \"url\": \"https://www.atlanticcouncil.org/feed/\", \"type\": \"rss\"},\n",
    "    ],\n",
    "\n",
    "    # === WIRE SERVICES & MAJOR NEWS ===\n",
    "    \"wire\": [\n",
    "        {\"name\": \"Reuters World\", \"url\": \"https://www.reutersagency.com/feed/?taxonomy=best-topics&post_type=best\", \"type\": \"rss\"},\n",
    "        {\"name\": \"AP News\", \"url\": \"https://rsshub.app/apnews/topics/world-news\", \"type\": \"rss\"},\n",
    "        {\"name\": \"BBC World\", \"url\": \"http://feeds.bbci.co.uk/news/world/rss.xml\", \"type\": \"rss\"},\n",
    "        {\"name\": \"Al Jazeera\", \"url\": \"https://www.aljazeera.com/xml/rss/all.xml\", \"type\": \"rss\"},\n",
    "        {\"name\": \"France 24\", \"url\": \"https://www.france24.com/en/rss\", \"type\": \"rss\"},\n",
    "        {\"name\": \"DW News\", \"url\": \"https://rss.dw.com/rdf/rss-en-all\", \"type\": \"rss\"},\n",
    "    ],\n",
    "\n",
    "    # === REGIONAL SPECIALISTS ===\n",
    "    \"regional\": [\n",
    "        {\"name\": \"South China Morning Post\", \"url\": \"https://www.scmp.com/rss/91/feed\", \"type\": \"rss\"},\n",
    "        {\"name\": \"Nikkei Asia\", \"url\": \"https://asia.nikkei.com/rss/feed/nar\", \"type\": \"rss\"},\n",
    "        {\"name\": \"The Moscow Times\", \"url\": \"https://www.themoscowtimes.com/rss/news\", \"type\": \"rss\"},\n",
    "        {\"name\": \"Times of Israel\", \"url\": \"https://www.timesofisrael.com/feed/\", \"type\": \"rss\"},\n",
    "        {\"name\": \"Middle East Eye\", \"url\": \"https://www.middleeasteye.net/rss\", \"type\": \"rss\"},\n",
    "        {\"name\": \"Kyiv Independent\", \"url\": \"https://kyivindependent.com/feed/\", \"type\": \"rss\"},\n",
    "        {\"name\": \"ISW\", \"url\": \"https://www.understandingwar.org/rss.xml\", \"type\": \"rss\"},\n",
    "    ],\n",
    "\n",
    "    # === INTELLIGENCE & SECURITY ===\n",
    "    \"intel\": [\n",
    "        {\"name\": \"Bellingcat\", \"url\": \"https://www.bellingcat.com/feed/\", \"type\": \"rss\"},\n",
    "        {\"name\": \"The Intercept\", \"url\": \"https://theintercept.com/feed/?rss\", \"type\": \"rss\"},\n",
    "        {\"name\": \"Lawfare\", \"url\": \"https://www.lawfaremedia.org/rss.xml\", \"type\": \"rss\"},\n",
    "        {\"name\": \"Just Security\", \"url\": \"https://www.justsecurity.org/feed/\", \"type\": \"rss\"},\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Count total sources\n",
    "total_sources = sum(len(sources) for sources in NEWS_SOURCES.values())\n",
    "print(f\"üì∞ Loaded {total_sources} news sources across {len(NEWS_SOURCES)} categories\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÑ Step 4: News Fetcher Engine\n",
    "\n",
    "Core engine for fetching and parsing news from multiple sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feedparser\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil import parser as date_parser\n",
    "import time\n",
    "import re\n",
    "from typing import List, Dict, Optional\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import hashlib\n",
    "\n",
    "class NewsFetcher:\n",
    "    \"\"\"Multi-source news aggregation engine.\"\"\"\n",
    "\n",
    "    def __init__(self, sources: Dict):\n",
    "        self.sources = sources\n",
    "        self.headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',\n",
    "            'Accept': 'application/rss+xml, application/xml, text/xml, */*',\n",
    "        }\n",
    "        self.session = requests.Session()\n",
    "        self.session.headers.update(self.headers)\n",
    "\n",
    "    def fetch_rss(self, source: Dict) -> List[Dict]:\n",
    "        \"\"\"Fetch and parse RSS feed.\"\"\"\n",
    "        articles = []\n",
    "        try:\n",
    "            response = self.session.get(source['url'], timeout=15)\n",
    "            feed = feedparser.parse(response.content)\n",
    "\n",
    "            for entry in feed.entries[:20]:  # Limit per source\n",
    "                # Parse publication date\n",
    "                pub_date = None\n",
    "                for date_field in ['published', 'pubDate', 'updated', 'created']:\n",
    "                    if hasattr(entry, date_field) and getattr(entry, date_field):\n",
    "                        try:\n",
    "                            pub_date = date_parser.parse(getattr(entry, date_field))\n",
    "                            break\n",
    "                        except:\n",
    "                            continue\n",
    "\n",
    "                # Skip articles older than 48 hours\n",
    "                if pub_date:\n",
    "                    if pub_date.tzinfo is None:\n",
    "                        pub_date = pub_date.replace(tzinfo=pytz.UTC)\n",
    "                    age = datetime.now(pytz.UTC) - pub_date\n",
    "                    if age > timedelta(hours=48):\n",
    "                        continue\n",
    "\n",
    "                # Clean title\n",
    "                title = entry.get('title', '').strip()\n",
    "                title = re.sub(r'\\s+', ' ', title)\n",
    "\n",
    "                # Get description/summary\n",
    "                description = entry.get('summary', entry.get('description', ''))\n",
    "                if description:\n",
    "                    description = BeautifulSoup(description, 'html.parser').get_text()\n",
    "                    description = re.sub(r'\\s+', ' ', description).strip()[:300]\n",
    "\n",
    "                if title and len(title) > 10:\n",
    "                    articles.append({\n",
    "                        'title': title,\n",
    "                        'url': entry.get('link', ''),\n",
    "                        'source': source['name'],\n",
    "                        'published': pub_date,\n",
    "                        'description': description,\n",
    "                        'id': hashlib.md5(title.encode()).hexdigest()[:8]\n",
    "                    })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö†Ô∏è Error fetching {source['name']}: {str(e)[:50]}\")\n",
    "\n",
    "        return articles\n",
    "\n",
    "    def fetch_all(self, max_workers: int = 10) -> List[Dict]:\n",
    "        \"\"\"Fetch from all sources concurrently.\"\"\"\n",
    "        all_articles = []\n",
    "        all_sources = []\n",
    "\n",
    "        # Flatten sources\n",
    "        for category, sources in self.sources.items():\n",
    "            for source in sources:\n",
    "                source['category'] = category\n",
    "                all_sources.append(source)\n",
    "\n",
    "        print(f\"\\nüîÑ Fetching from {len(all_sources)} sources...\\n\")\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            future_to_source = {\n",
    "                executor.submit(self.fetch_rss, source): source\n",
    "                for source in all_sources if source['type'] == 'rss'\n",
    "            }\n",
    "\n",
    "            for i, future in enumerate(as_completed(future_to_source)):\n",
    "                source = future_to_source[future]\n",
    "                try:\n",
    "                    articles = future.result()\n",
    "                    if articles:\n",
    "                        all_articles.extend(articles)\n",
    "                        print(f\"   ‚úì {source['name']}: {len(articles)} articles\")\n",
    "                    else:\n",
    "                        print(f\"   ‚óã {source['name']}: No recent articles\")\n",
    "                except Exception as e:\n",
    "                    print(f\"   ‚úó {source['name']}: Failed\")\n",
    "\n",
    "        # Deduplicate by title similarity\n",
    "        seen_titles = set()\n",
    "        unique_articles = []\n",
    "        for article in all_articles:\n",
    "            title_key = re.sub(r'[^a-z0-9]', '', article['title'].lower())[:50]\n",
    "            if title_key not in seen_titles:\n",
    "                seen_titles.add(title_key)\n",
    "                unique_articles.append(article)\n",
    "\n",
    "        print(f\"\\nüìä Total: {len(unique_articles)} unique articles (from {len(all_articles)} raw)\")\n",
    "        return unique_articles\n",
    "\n",
    "# Initialize fetcher\n",
    "fetcher = NewsFetcher(NEWS_SOURCES)\n",
    "print(\"‚úÖ News Fetcher initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ Step 5: AI Categorization Engine\n",
    "\n",
    "Uses Claude AI to intelligently categorize and prioritize headlines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import anthropic\nimport json\n\nclass AICategorizor:\n    \"\"\"AI-powered news categorization and prioritization.\"\"\"\n\n    # 8 sections for the 3x3 grid (center is IEJ logo)\n    SECTIONS = [\n        \"GLOBE\",         # Global/international stories\n        \"US\",            # United States\n        \"EUROPE\",        # Europe including Russia/Ukraine\n        \"ASIA\",          # Asia-Pacific region\n        \"MIDDLE_EAST\",   # Middle East\n        \"CONFLICTS\",     # Active conflicts, military action\n        \"CYBERSECURITY\", # Cyber attacks, hacking, digital warfare\n        \"FINANCE\",       # Defense industry, sanctions, economic warfare\n    ]\n\n    PRIORITIES = [\"BREAKING\", \"HIGH\", \"STANDARD\"]\n\n    def __init__(self, api_key: str):\n        self.client = anthropic.Anthropic(api_key=api_key)\n\n    def categorize_batch(self, articles: List[Dict], batch_size: int = 30) -> List[Dict]:\n        \"\"\"Categorize articles in batches for efficiency.\"\"\"\n        categorized = []\n\n        for i in range(0, len(articles), batch_size):\n            batch = articles[i:i+batch_size]\n            print(f\"   Processing batch {i//batch_size + 1}/{(len(articles)-1)//batch_size + 1}...\")\n\n            headlines_text = \"\\n\".join([\n                f\"{j+1}. [{a['source']}] {a['title']}\"\n                for j, a in enumerate(batch)\n            ])\n\n            prompt = f\"\"\"Categorize these geopolitics/defense headlines into sections.\n\nSECTIONS (pick ONE per headline):\n- GLOBE: International diplomacy, global institutions, multi-region stories, UN, treaties\n- US: United States domestic, Pentagon, Washington policy, Congress, military branches\n- EUROPE: European nations, NATO, EU, UK, Russia, Ukraine conflict, Balkans\n- ASIA: China, Taiwan, Japan, Korea, Indo-Pacific, ASEAN, Australia, India\n- MIDDLE_EAST: Israel, Iran, Gaza, Yemen, Syria, Iraq, Gulf states, Lebanon\n- CONFLICTS: Active warfare, military strikes, battles, combat operations, casualties\n- CYBERSECURITY: Cyber attacks, hacking, data breaches, digital warfare, ransomware, espionage\n- FINANCE: Defense contracts, sanctions, economic warfare, arms deals, military spending, trade wars\n\nPRIORITY:\n- BREAKING: Major developing events, escalations\n- HIGH: Important developments  \n- STANDARD: Regular news\n\nHeadlines:\n{headlines_text}\n\nReturn ONLY a JSON array:\n[{{\"index\": 1, \"section\": \"SECTION\", \"priority\": \"PRIORITY\"}}, ...]\"\"\"\n\n            try:\n                response = self.client.messages.create(\n                    model=\"claude-sonnet-4-20250514\",\n                    max_tokens=2000,\n                    messages=[{\"role\": \"user\", \"content\": prompt}]\n                )\n\n                response_text = response.content[0].text.strip()\n                json_match = re.search(r'\\[.*\\]', response_text, re.DOTALL)\n                \n                if json_match:\n                    results = json.loads(json_match.group())\n                    for result in results:\n                        idx = result.get('index', 0) - 1\n                        if 0 <= idx < len(batch):\n                            article = batch[idx].copy()\n                            article['section'] = result.get('section', 'GLOBE')\n                            article['priority'] = result.get('priority', 'STANDARD')\n                            categorized.append(article)\n                else:\n                    for article in batch:\n                        article['section'] = self._guess_section(article['title'])\n                        article['priority'] = self._guess_priority(article['title'])\n                        categorized.append(article)\n\n            except Exception as e:\n                print(f\"   AI error: {e}\")\n                for article in batch:\n                    article['section'] = self._guess_section(article['title'])\n                    article['priority'] = self._guess_priority(article['title'])\n                    categorized.append(article)\n\n            time.sleep(0.3)\n\n        return categorized\n\n    def _guess_section(self, title: str) -> str:\n        \"\"\"Fallback section detection based on keywords.\"\"\"\n        t = title.lower()\n        \n        # Cybersecurity\n        if any(kw in t for kw in ['cyber', 'hack', 'breach', 'ransomware', 'malware', 'phishing', 'data leak', 'encryption', 'zero-day', 'vulnerability', 'apt', 'espionage']):\n            return 'CYBERSECURITY'\n        \n        # Finance/Economic\n        if any(kw in t for kw in ['sanction', 'contract', 'billion', 'million', 'defense budget', 'arms deal', 'lockheed', 'raytheon', 'boeing', 'northrop', 'trade war', 'tariff', 'economic']):\n            return 'FINANCE'\n        \n        # Conflicts (active combat)\n        if any(kw in t for kw in ['strike', 'attack', 'combat', 'battle', 'offensive', 'airstrike', 'missile strike', 'killed', 'casualties', 'wounded', 'bombing', 'shelling']):\n            return 'CONFLICTS'\n        \n        # Regional matching\n        if any(kw in t for kw in ['pentagon', 'washington', 'congress', 'u.s.', 'us ', 'american', 'biden', 'trump', 'white house', 'state department', 'cia', 'fbi']):\n            return 'US'\n        if any(kw in t for kw in ['china', 'taiwan', 'japan', 'korea', 'beijing', 'tokyo', 'pacific', 'indo-pacific', 'asean', 'philippines', 'vietnam', 'australia', 'india', 'modi']):\n            return 'ASIA'\n        if any(kw in t for kw in ['europe', 'nato', 'eu ', 'ukraine', 'russia', 'moscow', 'kyiv', 'britain', 'uk ', 'france', 'germany', 'poland', 'baltic', 'putin', 'zelensky']):\n            return 'EUROPE'\n        if any(kw in t for kw in ['israel', 'iran', 'gaza', 'hamas', 'hezbollah', 'yemen', 'houthi', 'syria', 'iraq', 'saudi', 'gulf', 'lebanon', 'tehran', 'netanyahu']):\n            return 'MIDDLE_EAST'\n        \n        return 'GLOBE'\n\n    def _guess_priority(self, title: str) -> str:\n        \"\"\"Fallback priority detection.\"\"\"\n        t = title.lower()\n        if any(kw in t for kw in ['breaking', 'urgent', 'just in', 'developing', 'live:']):\n            return 'BREAKING'\n        if any(kw in t for kw in ['attack', 'strike', 'kills', 'dead', 'explosion', 'invasion', 'launches']):\n            return 'HIGH'\n        return 'STANDARD'\n\n# Initialize\nif ANTHROPIC_API_KEY and ANTHROPIC_API_KEY != 'your-anthropic-api-key-here':\n    ai_categorizer = AICategorizor(ANTHROPIC_API_KEY)\n    print(\"AI Categorizer initialized with Claude API\")\nelse:\n    ai_categorizer = AICategorizor(\"dummy\")\n    print(\"AI Categorizer using keyword fallback (no API key)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé® Step 6: Website Generator\n",
    "\n",
    "Generates a modern, responsive HTML website with the aggregated news."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "class WebsiteGenerator:\n    \"\"\"Generates Drudge-style dark theme news site with IEJ branding in center.\"\"\"\n\n    def __init__(self, site_title: str, site_subtitle: str, timezone: str):\n        self.site_title = site_title\n        self.site_subtitle = site_subtitle\n        self.tz = pytz.timezone(timezone)\n\n    def generate(self, articles: List[Dict]) -> str:\n        \"\"\"Generate dark theme HTML page with 3x3 grid, IEJ in center.\"\"\"\n        now = datetime.now(self.tz)\n        date_display = now.strftime(\"%B %d, %Y\")\n        time_display = now.strftime(\"%I:%M %p %Z\")\n\n        # Organize articles by section\n        sections = self._organize_by_section(articles)\n\n        html = f'''<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <meta name=\"description\" content=\"{self.site_subtitle}\">\n    <title>{self.site_title} - {self.site_subtitle}</title>\n    <link rel=\"preconnect\" href=\"https://fonts.googleapis.com\">\n    <link href=\"https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600&display=swap\" rel=\"stylesheet\">\n    <style>\n        * {{ margin: 0; padding: 0; box-sizing: border-box; }}\n        \n        body {{\n            font-family: 'Inter', Arial, sans-serif;\n            font-size: 13px;\n            line-height: 1.35;\n            background: #0d1117;\n            color: #c9d1d9;\n            min-height: 100vh;\n        }}\n\n        /* Main grid - 3x3 with IEJ in center */\n        .main-grid {{\n            display: grid;\n            grid-template-columns: 1fr 1fr 1fr;\n            min-height: 100vh;\n        }}\n\n        /* Section styling */\n        .section {{\n            border-right: 1px solid #21262d;\n            border-bottom: 1px solid #21262d;\n            display: flex;\n            flex-direction: column;\n        }}\n\n        .section:nth-child(3n) {{\n            border-right: none;\n        }}\n\n        .section:nth-child(7),\n        .section:nth-child(8),\n        .section:nth-child(9) {{\n            border-bottom: none;\n        }}\n\n        .section-header {{\n            background: #161b22;\n            color: #8b949e;\n            padding: 10px 12px;\n            font-size: 11px;\n            font-weight: 600;\n            text-transform: uppercase;\n            letter-spacing: 1.5px;\n            border-bottom: 1px solid #21262d;\n        }}\n\n        /* Center IEJ cell */\n        .center-cell {{\n            display: flex;\n            flex-direction: column;\n            align-items: center;\n            justify-content: center;\n            background: linear-gradient(135deg, #0d1117 0%, #161b22 50%, #0d1117 100%);\n            border-right: 1px solid #21262d;\n            border-bottom: 1px solid #21262d;\n        }}\n\n        .center-cell .logo {{\n            font-family: 'Inter', Arial, sans-serif;\n            font-size: 56px;\n            font-weight: 600;\n            color: #58a6ff;\n            letter-spacing: 8px;\n            text-shadow: 0 0 30px rgba(88, 166, 255, 0.3);\n        }}\n\n        .center-cell .tagline {{\n            font-size: 10px;\n            color: #8b949e;\n            text-transform: uppercase;\n            letter-spacing: 3px;\n            margin-top: 8px;\n        }}\n\n        .center-cell .date {{\n            font-size: 11px;\n            color: #58a6ff;\n            margin-top: 12px;\n            font-weight: 500;\n        }}\n\n        .center-cell .time {{\n            font-size: 10px;\n            color: #6e7681;\n            margin-top: 4px;\n        }}\n\n        /* Headlines list */\n        .headlines {{\n            padding: 10px;\n            flex: 1;\n            overflow-y: auto;\n        }}\n\n        .headline {{\n            margin-bottom: 10px;\n            padding-bottom: 10px;\n            border-bottom: 1px solid #21262d;\n        }}\n\n        .headline:last-child {{\n            border-bottom: none;\n            margin-bottom: 0;\n            padding-bottom: 0;\n        }}\n\n        .headline a {{\n            color: #c9d1d9;\n            text-decoration: none;\n            font-size: 13px;\n            line-height: 1.4;\n            display: block;\n            transition: color 0.15s ease;\n        }}\n\n        .headline a:hover {{\n            color: #58a6ff;\n        }}\n\n        .headline.breaking a {{\n            color: #f85149;\n            font-weight: 500;\n        }}\n\n        .headline.high a {{\n            color: #d29922;\n        }}\n\n        .headline .src {{\n            font-size: 10px;\n            color: #6e7681;\n            text-transform: uppercase;\n            margin-top: 3px;\n            letter-spacing: 0.5px;\n        }}\n\n        /* Footer */\n        .footer {{\n            grid-column: 1 / -1;\n            text-align: center;\n            padding: 12px;\n            background: #161b22;\n            border-top: 1px solid #21262d;\n            font-size: 10px;\n            color: #6e7681;\n        }}\n\n        /* Responsive */\n        @media (max-width: 900px) {{\n            .main-grid {{\n                grid-template-columns: 1fr;\n            }}\n            .section {{\n                border-right: none;\n            }}\n            .center-cell .logo {{\n                font-size: 42px;\n            }}\n        }}\n\n        /* Scrollbar styling */\n        .headlines::-webkit-scrollbar {{\n            width: 6px;\n        }}\n        .headlines::-webkit-scrollbar-track {{\n            background: #0d1117;\n        }}\n        .headlines::-webkit-scrollbar-thumb {{\n            background: #30363d;\n            border-radius: 3px;\n        }}\n    </style>\n</head>\n<body>\n    <div class=\"main-grid\">\n        <!-- Row 1: Globe | US | Europe -->\n        {self._generate_section('GLOBE', sections.get('GLOBE', []))}\n        {self._generate_section('US', sections.get('US', []))}\n        {self._generate_section('EUROPE', sections.get('EUROPE', []))}\n        \n        <!-- Row 2: Asia | IEJ Center | Middle East -->\n        {self._generate_section('ASIA', sections.get('ASIA', []))}\n        \n        <div class=\"center-cell\">\n            <div class=\"logo\">IEJ</div>\n            <div class=\"tagline\">Intel Brief</div>\n            <div class=\"date\">{date_display}</div>\n            <div class=\"time\">{time_display}</div>\n        </div>\n        \n        {self._generate_section('MIDDLE EAST', sections.get('MIDDLE_EAST', []))}\n        \n        <!-- Row 3: Conflicts | Cybersecurity | Finance -->\n        {self._generate_section('CONFLICTS', sections.get('CONFLICTS', []))}\n        {self._generate_section('CYBERSECURITY', sections.get('CYBERSECURITY', []))}\n        {self._generate_section('FINANCE', sections.get('FINANCE', []))}\n    </div>\n\n    <footer class=\"footer\">\n        {len(set(a.get('source', '') for a in articles))} Sources | AI-Aggregated | {time_display}\n    </footer>\n</body>\n</html>'''\n\n        return html\n\n    def _organize_by_section(self, articles: List[Dict]) -> Dict:\n        \"\"\"Organize articles by section.\"\"\"\n        sections = {s: [] for s in ['GLOBE', 'US', 'EUROPE', 'ASIA', 'MIDDLE_EAST', 'CONFLICTS', 'CYBERSECURITY', 'FINANCE']}\n        \n        priority_order = {'BREAKING': 0, 'HIGH': 1, 'STANDARD': 2}\n        sorted_articles = sorted(\n            articles,\n            key=lambda x: (\n                priority_order.get(x.get('priority', 'STANDARD'), 2),\n                -(x.get('published') or datetime.min.replace(tzinfo=pytz.UTC)).timestamp()\n            )\n        )\n        \n        for article in sorted_articles:\n            section = article.get('section', 'GLOBE')\n            if section in sections and len(sections[section]) < HEADLINES_PER_SECTION:\n                sections[section].append(article)\n        \n        return sections\n\n    def _generate_section(self, title: str, articles: List[Dict]) -> str:\n        \"\"\"Generate a section with headlines.\"\"\"\n        headlines_html = ''\n        for article in articles:\n            priority_class = ''\n            if article.get('priority') == 'BREAKING':\n                priority_class = 'breaking'\n            elif article.get('priority') == 'HIGH':\n                priority_class = 'high'\n            \n            headlines_html += f'''\n            <div class=\"headline {priority_class}\">\n                <a href=\"{article.get('url', '#')}\" target=\"_blank\">{article.get('title', 'Untitled')}</a>\n                <div class=\"src\">{article.get('source', '')}</div>\n            </div>'''\n        \n        if not headlines_html:\n            headlines_html = '<div class=\"headline\"><span style=\"color:#6e7681;\">No recent headlines</span></div>'\n        \n        return f'''\n        <div class=\"section\">\n            <div class=\"section-header\">{title}</div>\n            <div class=\"headlines\">{headlines_html}</div>\n        </div>'''\n\n# Initialize generator\ngenerator = WebsiteGenerator(SITE_TITLE, SITE_SUBTITLE, TIMEZONE)\nprint(\"Website Generator initialized - Dark theme 3x3 grid\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Step 7: GitHub Pages Deployment\n",
    "\n",
    "Automatically deploy the generated website to GitHub Pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from github import Github\n",
    "import base64\n",
    "\n",
    "class GitHubDeployer:\n",
    "    \"\"\"Deploy generated website to GitHub Pages.\"\"\"\n",
    "\n",
    "    def __init__(self, token: str, repo_name: str, branch: str = \"gh-pages\"):\n",
    "        self.github = Github(token)\n",
    "        self.repo = self.github.get_repo(repo_name)\n",
    "        self.branch = branch\n",
    "\n",
    "    def deploy(self, html_content: str, filename: str = \"index.html\") -> str:\n",
    "        \"\"\"Deploy HTML file to GitHub Pages.\"\"\"\n",
    "        try:\n",
    "            # Check if branch exists\n",
    "            try:\n",
    "                self.repo.get_branch(self.branch)\n",
    "            except:\n",
    "                # Create branch from main/master\n",
    "                default_branch = self.repo.default_branch\n",
    "                source = self.repo.get_branch(default_branch)\n",
    "                self.repo.create_git_ref(\n",
    "                    ref=f\"refs/heads/{self.branch}\",\n",
    "                    sha=source.commit.sha\n",
    "                )\n",
    "                print(f\"   Created branch: {self.branch}\")\n",
    "\n",
    "            # Check if file exists\n",
    "            try:\n",
    "                file = self.repo.get_contents(filename, ref=self.branch)\n",
    "                # Update existing file\n",
    "                self.repo.update_file(\n",
    "                    path=filename,\n",
    "                    message=f\"Update {filename} - {datetime.now().strftime('%Y-%m-%d %H:%M')}\",\n",
    "                    content=html_content,\n",
    "                    sha=file.sha,\n",
    "                    branch=self.branch\n",
    "                )\n",
    "                print(f\"   ‚úì Updated {filename}\")\n",
    "            except:\n",
    "                # Create new file\n",
    "                self.repo.create_file(\n",
    "                    path=filename,\n",
    "                    message=f\"Create {filename} - {datetime.now().strftime('%Y-%m-%d %H:%M')}\",\n",
    "                    content=html_content,\n",
    "                    branch=self.branch\n",
    "                )\n",
    "                print(f\"   ‚úì Created {filename}\")\n",
    "\n",
    "            # Return the GitHub Pages URL\n",
    "            owner = self.repo.owner.login\n",
    "            repo_name = self.repo.name\n",
    "            return f\"https://{owner}.github.io/{repo_name}/\"\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö†Ô∏è Deploy error: {e}\")\n",
    "            return None\n",
    "\n",
    "# Initialize deployer if token is available\n",
    "if GITHUB_TOKEN:\n",
    "    deployer = GitHubDeployer(GITHUB_TOKEN, GITHUB_REPO, GITHUB_BRANCH)\n",
    "    print(\"‚úÖ GitHub Deployer initialized\")\n",
    "else:\n",
    "    deployer = None\n",
    "    print(\"‚ö†Ô∏è GitHub Deployer not initialized - will save locally only\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ñ∂Ô∏è Step 8: Run the Aggregator\n",
    "\n",
    "Execute the complete pipeline: Fetch ‚Üí Categorize ‚Üí Generate ‚Üí Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def run_aggregator(deploy: bool = True, save_local: bool = True):\n    \"\"\"\n    Run the complete news aggregation pipeline.\n\n    Args:\n        deploy: Whether to deploy to GitHub Pages\n        save_local: Whether to save HTML file locally\n    \"\"\"\n    print(\"=\"*60)\n    print(\"IEJ GEOPOLITICS NEWS AGGREGATOR\")\n    print(f\"Started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n    print(\"=\"*60)\n\n    # Step 1: Fetch news\n    print(\"\\n[1/4] Fetching News...\")\n    articles = fetcher.fetch_all()\n\n    if not articles:\n        print(\"\\nNo articles fetched. Check your internet connection.\")\n        return None, None\n\n    # Step 2: AI Categorization\n    print(\"\\n[2/4] Categorizing Headlines...\")\n    if ANTHROPIC_API_KEY and ANTHROPIC_API_KEY != 'your-anthropic-api-key-here':\n        categorized = ai_categorizer.categorize_batch(articles)\n    else:\n        print(\"   Using keyword-based categorization...\")\n        categorized = []\n        for article in articles:\n            article['section'] = ai_categorizer._guess_section(article['title'])\n            article['priority'] = ai_categorizer._guess_priority(article['title'])\n            categorized.append(article)\n\n    # Print summary\n    print(\"\\nCategorization Summary:\")\n    sections_count = {}\n    for a in categorized:\n        s = a.get('section', 'GLOBE')\n        sections_count[s] = sections_count.get(s, 0) + 1\n    \n    for section, count in sorted(sections_count.items()):\n        print(f\"   {section}: {count}\")\n\n    # Step 3: Generate HTML\n    print(\"\\n[3/4] Generating Website...\")\n    html = generator.generate(categorized)\n    print(f\"   Generated {len(html):,} bytes\")\n\n    # Step 4: Save locally\n    if save_local:\n        with open(OUTPUT_FILENAME, 'w', encoding='utf-8') as f:\n            f.write(html)\n        print(f\"   Saved to: {OUTPUT_FILENAME}\")\n\n    # Step 5: Deploy to GitHub Pages\n    if deploy and deployer:\n        print(\"\\n[4/4] Deploying to GitHub Pages...\")\n        url = deployer.deploy(html, OUTPUT_FILENAME)\n        if url:\n            print(f\"\\nDEPLOYMENT SUCCESSFUL!\")\n            print(f\"Live at: {url}\")\n    else:\n        print(\"\\n[4/4] Skipping deployment (no token)\")\n\n    print(\"\\n\" + \"=\"*60)\n    print(f\"COMPLETE - {len(categorized)} headlines aggregated\")\n    print(\"=\"*60)\n\n    return html, categorized\n\n# Run the aggregator\nhtml_output, articles_data = run_aggregator(deploy=False, save_local=True)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üëÄ Step 9: Preview the Website\n",
    "\n",
    "Display the generated website directly in Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "\n",
    "# Display in an iframe\n",
    "if html_output:\n",
    "    display(HTML(f'''\n",
    "    <div style=\"border: 1px solid #333; border-radius: 8px; overflow: hidden; margin: 20px 0;\">\n",
    "        <iframe srcdoc=\"{html_output.replace('\"', '&quot;')}\" \n",
    "                style=\"width: 100%; height: 800px; border: none;\"\n",
    "                sandbox=\"allow-same-origin allow-scripts allow-popups allow-forms\">\n",
    "        </iframe>\n",
    "    </div>\n",
    "    '''))\n",
    "    print(\"üëÜ Preview above. Scroll to explore all sections.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚è∞ Step 10: Schedule Automatic Updates (Optional)\n",
    "\n",
    "Set up automatic updates using Colab's scheduling or external services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def scheduled_run(interval_minutes: int = 60, max_runs: int = 24):\n",
    "    \"\"\"\n",
    "    Run the aggregator on a schedule.\n",
    "\n",
    "    Args:\n",
    "        interval_minutes: Time between updates\n",
    "        max_runs: Maximum number of runs before stopping\n",
    "    \"\"\"\n",
    "    print(f\"üïê Starting scheduled runs every {interval_minutes} minutes\")\n",
    "    print(f\"   Max runs: {max_runs}\")\n",
    "    print(f\"   Press Runtime > Interrupt to stop\\n\")\n",
    "\n",
    "    for i in range(max_runs):\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"RUN {i+1}/{max_runs}\")\n",
    "        print(f\"{'='*50}\")\n",
    "\n",
    "        try:\n",
    "            run_aggregator(deploy=True, save_local=True)\n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚ùå Error in run {i+1}: {e}\")\n",
    "\n",
    "        if i < max_runs - 1:\n",
    "            next_run = datetime.now() + timedelta(minutes=interval_minutes)\n",
    "            print(f\"\\n‚è∞ Next run at: {next_run.strftime('%H:%M:%S')}\")\n",
    "            time.sleep(interval_minutes * 60)\n",
    "\n",
    "    print(\"\\n‚úÖ Scheduled runs complete!\")\n",
    "\n",
    "# Uncomment to run on schedule:\n",
    "# scheduled_run(interval_minutes=60, max_runs=24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì• Step 11: Download the HTML File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import files\n",
    "    files.download(OUTPUT_FILENAME)\n",
    "    print(f\"‚úÖ Downloaded: {OUTPUT_FILENAME}\")\n",
    "except:\n",
    "    print(f\"üìÅ File saved locally: {OUTPUT_FILENAME}\")\n",
    "    print(\"   (Download manually if not in Colab)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìñ Usage Guide\n",
    "\n",
    "### Quick Start\n",
    "1. Set your `ANTHROPIC_API_KEY` in Colab secrets\n",
    "2. Run all cells (Runtime > Run all)\n",
    "3. Preview your site in Step 9\n",
    "4. Download in Step 11\n",
    "\n",
    "### GitHub Pages Deployment\n",
    "1. Create a GitHub Personal Access Token with `repo` scope\n",
    "2. Add as `GITHUB_TOKEN` in Colab secrets\n",
    "3. Update `GITHUB_REPO` with your repository\n",
    "4. Enable GitHub Pages in repo settings (source: `gh-pages` branch)\n",
    "\n",
    "### Customization\n",
    "- Edit `NEWS_SOURCES` to add/remove news sources\n",
    "- Modify `WebsiteGenerator` CSS for different themes\n",
    "- Adjust `PRIORITY_KEYWORDS` for different focus areas\n",
    "\n",
    "### Tips\n",
    "- Without an Anthropic API key, the system uses keyword-based categorization (less accurate)\n",
    "- Run during off-peak hours for faster RSS fetching\n",
    "- Use scheduled runs for continuous updates\n",
    "\n",
    "---\n",
    "\n",
    "*Built with ‚ù§Ô∏è for geopolitics enthusiasts*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}