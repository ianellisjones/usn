{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<a href=\"https://colab.research.google.com/github/ianellisjones/usn/blob/main/Geopolitics_News_Aggregator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n\n# IEJ - GEOPOLITICS NEWS AGGREGATOR\n\n**Drudge-Style AI-Powered News Intelligence**\n\nA dense, fast-loading news aggregation site inspired by the Drudge Report but focused on geopolitics, defense, and global security. AI automatically scans 35+ sources, categorizes headlines, and generates a clean website.\n\n### Layout\n```\n+----------+----------+----------+\n|  GLOBE   |    US    |  EUROPE  |\n+----------+----------+----------+\n|   ASIA   |   IEJ    | MIDEAST  |\n+----------+----------+----------+\n|        CONFLICTS               |\n+--------------------------------+\n```\n\n### Features\n- **Dense Headlines**: 40-50 headlines on one page, just like Drudge\n- **6 Sections**: Globe, US, Europe, Asia, Middle East, Conflicts\n- **IEJ Branding**: Your logo prominently in the center\n- **AI Categorization**: Claude automatically sorts headlines by region and priority\n- **Auto-Deploy**: Push directly to GitHub Pages\n\n---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Step 1: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%shell\n",
    "# Install required packages\n",
    "pip install feedparser anthropic requests beautifulsoup4 newspaper3k lxml_html_clean python-dateutil pytz --quiet\n",
    "\n",
    "# For GitHub deployment\n",
    "pip install PyGithub --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîë Step 2: Configuration\n",
    "\n",
    "Set your API keys and preferences here. You can store these in Colab secrets for security."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\nfrom datetime import datetime\nimport pytz\n\n# =============================================================================\n# CONFIGURATION - Edit these values\n# =============================================================================\n\n# Option 1: Use Colab secrets (recommended)\ntry:\n    from google.colab import userdata\n    ANTHROPIC_API_KEY = userdata.get('ANTHROPIC_API_KEY')\n    GITHUB_TOKEN = userdata.get('GITHUB_TOKEN')  # Optional: for auto-deploy\nexcept:\n    # Option 2: Set directly (not recommended for production)\n    ANTHROPIC_API_KEY = \"your-anthropic-api-key-here\"\n    GITHUB_TOKEN = None  # Optional\n\n# Site Configuration\nSITE_TITLE = \"IEJ\"\nSITE_SUBTITLE = \"Global Intelligence Briefing\"\nTIMEZONE = \"US/Eastern\"\n\n# GitHub Pages Configuration (optional)\nGITHUB_REPO = \"ianellisjones/usn\"  # Format: username/repo\nGITHUB_BRANCH = \"gh-pages\"\nOUTPUT_FILENAME = \"index.html\"\n\n# Layout Settings - Dense like Drudge\nHEADLINES_PER_SECTION = 8  # 6 sections x 8 = ~48 headlines\nTOTAL_HEADLINE_TARGET = 50\n\nprint(f\"Configuration loaded\")\nprint(f\"   Site: {SITE_TITLE}\")\nprint(f\"   Timezone: {TIMEZONE}\")\nprint(f\"   API Key: {'Set' if ANTHROPIC_API_KEY and ANTHROPIC_API_KEY != 'your-anthropic-api-key-here' else 'NOT SET'}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì∞ Step 3: News Sources Database\n",
    "\n",
    "Curated list of premium geopolitics and defense news sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# NEWS SOURCES - Organized by category\n",
    "# =============================================================================\n",
    "\n",
    "NEWS_SOURCES = {\n",
    "    # === DEFENSE & MILITARY ===\n",
    "    \"defense\": [\n",
    "        {\"name\": \"Defense News\", \"url\": \"https://www.defensenews.com/arc/outboundfeeds/rss/?outputType=xml\", \"type\": \"rss\"},\n",
    "        {\"name\": \"Breaking Defense\", \"url\": \"https://breakingdefense.com/feed/\", \"type\": \"rss\"},\n",
    "        {\"name\": \"Defense One\", \"url\": \"https://www.defenseone.com/rss/all/\", \"type\": \"rss\"},\n",
    "        {\"name\": \"Military Times\", \"url\": \"https://www.militarytimes.com/arc/outboundfeeds/rss/?outputType=xml\", \"type\": \"rss\"},\n",
    "        {\"name\": \"USNI News\", \"url\": \"https://news.usni.org/feed\", \"type\": \"rss\"},\n",
    "        {\"name\": \"War on the Rocks\", \"url\": \"https://warontherocks.com/feed/\", \"type\": \"rss\"},\n",
    "        {\"name\": \"The War Zone\", \"url\": \"https://www.thedrive.com/the-war-zone/feed\", \"type\": \"rss\"},\n",
    "        {\"name\": \"Naval News\", \"url\": \"https://www.navalnews.com/feed/\", \"type\": \"rss\"},\n",
    "        {\"name\": \"Air & Space Forces\", \"url\": \"https://www.airandspaceforces.com/feed/\", \"type\": \"rss\"},\n",
    "        {\"name\": \"Stars and Stripes\", \"url\": \"https://www.stripes.com/rss\", \"type\": \"rss\"},\n",
    "        {\"name\": \"Janes\", \"url\": \"https://www.janes.com/feeds/news\", \"type\": \"rss\"},\n",
    "    ],\n",
    "\n",
    "    # === GEOPOLITICS & FOREIGN POLICY ===\n",
    "    \"geopolitics\": [\n",
    "        {\"name\": \"Foreign Affairs\", \"url\": \"https://www.foreignaffairs.com/rss.xml\", \"type\": \"rss\"},\n",
    "        {\"name\": \"Foreign Policy\", \"url\": \"https://foreignpolicy.com/feed/\", \"type\": \"rss\"},\n",
    "        {\"name\": \"The Diplomat\", \"url\": \"https://thediplomat.com/feed/\", \"type\": \"rss\"},\n",
    "        {\"name\": \"CSIS\", \"url\": \"https://www.csis.org/analysis/feed\", \"type\": \"rss\"},\n",
    "        {\"name\": \"Brookings\", \"url\": \"https://www.brookings.edu/feed/\", \"type\": \"rss\"},\n",
    "        {\"name\": \"RAND\", \"url\": \"https://www.rand.org/news/press.xml\", \"type\": \"rss\"},\n",
    "        {\"name\": \"Carnegie Endowment\", \"url\": \"https://carnegieendowment.org/rss/solr/?fa=feeds\", \"type\": \"rss\"},\n",
    "        {\"name\": \"Council on Foreign Relations\", \"url\": \"https://www.cfr.org/rss/expert-brief\", \"type\": \"rss\"},\n",
    "        {\"name\": \"Atlantic Council\", \"url\": \"https://www.atlanticcouncil.org/feed/\", \"type\": \"rss\"},\n",
    "    ],\n",
    "\n",
    "    # === WIRE SERVICES & MAJOR NEWS ===\n",
    "    \"wire\": [\n",
    "        {\"name\": \"Reuters World\", \"url\": \"https://www.reutersagency.com/feed/?taxonomy=best-topics&post_type=best\", \"type\": \"rss\"},\n",
    "        {\"name\": \"AP News\", \"url\": \"https://rsshub.app/apnews/topics/world-news\", \"type\": \"rss\"},\n",
    "        {\"name\": \"BBC World\", \"url\": \"http://feeds.bbci.co.uk/news/world/rss.xml\", \"type\": \"rss\"},\n",
    "        {\"name\": \"Al Jazeera\", \"url\": \"https://www.aljazeera.com/xml/rss/all.xml\", \"type\": \"rss\"},\n",
    "        {\"name\": \"France 24\", \"url\": \"https://www.france24.com/en/rss\", \"type\": \"rss\"},\n",
    "        {\"name\": \"DW News\", \"url\": \"https://rss.dw.com/rdf/rss-en-all\", \"type\": \"rss\"},\n",
    "    ],\n",
    "\n",
    "    # === REGIONAL SPECIALISTS ===\n",
    "    \"regional\": [\n",
    "        {\"name\": \"South China Morning Post\", \"url\": \"https://www.scmp.com/rss/91/feed\", \"type\": \"rss\"},\n",
    "        {\"name\": \"Nikkei Asia\", \"url\": \"https://asia.nikkei.com/rss/feed/nar\", \"type\": \"rss\"},\n",
    "        {\"name\": \"The Moscow Times\", \"url\": \"https://www.themoscowtimes.com/rss/news\", \"type\": \"rss\"},\n",
    "        {\"name\": \"Times of Israel\", \"url\": \"https://www.timesofisrael.com/feed/\", \"type\": \"rss\"},\n",
    "        {\"name\": \"Middle East Eye\", \"url\": \"https://www.middleeasteye.net/rss\", \"type\": \"rss\"},\n",
    "        {\"name\": \"Kyiv Independent\", \"url\": \"https://kyivindependent.com/feed/\", \"type\": \"rss\"},\n",
    "        {\"name\": \"ISW\", \"url\": \"https://www.understandingwar.org/rss.xml\", \"type\": \"rss\"},\n",
    "    ],\n",
    "\n",
    "    # === INTELLIGENCE & SECURITY ===\n",
    "    \"intel\": [\n",
    "        {\"name\": \"Bellingcat\", \"url\": \"https://www.bellingcat.com/feed/\", \"type\": \"rss\"},\n",
    "        {\"name\": \"The Intercept\", \"url\": \"https://theintercept.com/feed/?rss\", \"type\": \"rss\"},\n",
    "        {\"name\": \"Lawfare\", \"url\": \"https://www.lawfaremedia.org/rss.xml\", \"type\": \"rss\"},\n",
    "        {\"name\": \"Just Security\", \"url\": \"https://www.justsecurity.org/feed/\", \"type\": \"rss\"},\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Count total sources\n",
    "total_sources = sum(len(sources) for sources in NEWS_SOURCES.values())\n",
    "print(f\"üì∞ Loaded {total_sources} news sources across {len(NEWS_SOURCES)} categories\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÑ Step 4: News Fetcher Engine\n",
    "\n",
    "Core engine for fetching and parsing news from multiple sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feedparser\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil import parser as date_parser\n",
    "import time\n",
    "import re\n",
    "from typing import List, Dict, Optional\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import hashlib\n",
    "\n",
    "class NewsFetcher:\n",
    "    \"\"\"Multi-source news aggregation engine.\"\"\"\n",
    "\n",
    "    def __init__(self, sources: Dict):\n",
    "        self.sources = sources\n",
    "        self.headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',\n",
    "            'Accept': 'application/rss+xml, application/xml, text/xml, */*',\n",
    "        }\n",
    "        self.session = requests.Session()\n",
    "        self.session.headers.update(self.headers)\n",
    "\n",
    "    def fetch_rss(self, source: Dict) -> List[Dict]:\n",
    "        \"\"\"Fetch and parse RSS feed.\"\"\"\n",
    "        articles = []\n",
    "        try:\n",
    "            response = self.session.get(source['url'], timeout=15)\n",
    "            feed = feedparser.parse(response.content)\n",
    "\n",
    "            for entry in feed.entries[:20]:  # Limit per source\n",
    "                # Parse publication date\n",
    "                pub_date = None\n",
    "                for date_field in ['published', 'pubDate', 'updated', 'created']:\n",
    "                    if hasattr(entry, date_field) and getattr(entry, date_field):\n",
    "                        try:\n",
    "                            pub_date = date_parser.parse(getattr(entry, date_field))\n",
    "                            break\n",
    "                        except:\n",
    "                            continue\n",
    "\n",
    "                # Skip articles older than 48 hours\n",
    "                if pub_date:\n",
    "                    if pub_date.tzinfo is None:\n",
    "                        pub_date = pub_date.replace(tzinfo=pytz.UTC)\n",
    "                    age = datetime.now(pytz.UTC) - pub_date\n",
    "                    if age > timedelta(hours=48):\n",
    "                        continue\n",
    "\n",
    "                # Clean title\n",
    "                title = entry.get('title', '').strip()\n",
    "                title = re.sub(r'\\s+', ' ', title)\n",
    "\n",
    "                # Get description/summary\n",
    "                description = entry.get('summary', entry.get('description', ''))\n",
    "                if description:\n",
    "                    description = BeautifulSoup(description, 'html.parser').get_text()\n",
    "                    description = re.sub(r'\\s+', ' ', description).strip()[:300]\n",
    "\n",
    "                if title and len(title) > 10:\n",
    "                    articles.append({\n",
    "                        'title': title,\n",
    "                        'url': entry.get('link', ''),\n",
    "                        'source': source['name'],\n",
    "                        'published': pub_date,\n",
    "                        'description': description,\n",
    "                        'id': hashlib.md5(title.encode()).hexdigest()[:8]\n",
    "                    })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö†Ô∏è Error fetching {source['name']}: {str(e)[:50]}\")\n",
    "\n",
    "        return articles\n",
    "\n",
    "    def fetch_all(self, max_workers: int = 10) -> List[Dict]:\n",
    "        \"\"\"Fetch from all sources concurrently.\"\"\"\n",
    "        all_articles = []\n",
    "        all_sources = []\n",
    "\n",
    "        # Flatten sources\n",
    "        for category, sources in self.sources.items():\n",
    "            for source in sources:\n",
    "                source['category'] = category\n",
    "                all_sources.append(source)\n",
    "\n",
    "        print(f\"\\nüîÑ Fetching from {len(all_sources)} sources...\\n\")\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            future_to_source = {\n",
    "                executor.submit(self.fetch_rss, source): source\n",
    "                for source in all_sources if source['type'] == 'rss'\n",
    "            }\n",
    "\n",
    "            for i, future in enumerate(as_completed(future_to_source)):\n",
    "                source = future_to_source[future]\n",
    "                try:\n",
    "                    articles = future.result()\n",
    "                    if articles:\n",
    "                        all_articles.extend(articles)\n",
    "                        print(f\"   ‚úì {source['name']}: {len(articles)} articles\")\n",
    "                    else:\n",
    "                        print(f\"   ‚óã {source['name']}: No recent articles\")\n",
    "                except Exception as e:\n",
    "                    print(f\"   ‚úó {source['name']}: Failed\")\n",
    "\n",
    "        # Deduplicate by title similarity\n",
    "        seen_titles = set()\n",
    "        unique_articles = []\n",
    "        for article in all_articles:\n",
    "            title_key = re.sub(r'[^a-z0-9]', '', article['title'].lower())[:50]\n",
    "            if title_key not in seen_titles:\n",
    "                seen_titles.add(title_key)\n",
    "                unique_articles.append(article)\n",
    "\n",
    "        print(f\"\\nüìä Total: {len(unique_articles)} unique articles (from {len(all_articles)} raw)\")\n",
    "        return unique_articles\n",
    "\n",
    "# Initialize fetcher\n",
    "fetcher = NewsFetcher(NEWS_SOURCES)\n",
    "print(\"‚úÖ News Fetcher initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ Step 5: AI Categorization Engine\n",
    "\n",
    "Uses Claude AI to intelligently categorize and prioritize headlines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import anthropic\nimport json\n\nclass AICategorizor:\n    \"\"\"AI-powered news categorization and prioritization.\"\"\"\n\n    # Updated sections per user request\n    SECTIONS = [\n        \"GLOBE\",       # Global/international stories\n        \"US\",          # United States\n        \"EUROPE\",      # Europe including Russia/Ukraine\n        \"ASIA\",        # Asia-Pacific region\n        \"MIDDLE_EAST\", # Middle East\n        \"CONFLICTS\",   # Active conflicts, military action\n    ]\n\n    PRIORITIES = [\"BREAKING\", \"HIGH\", \"STANDARD\"]\n\n    def __init__(self, api_key: str):\n        self.client = anthropic.Anthropic(api_key=api_key)\n\n    def categorize_batch(self, articles: List[Dict], batch_size: int = 30) -> List[Dict]:\n        \"\"\"Categorize articles in batches for efficiency.\"\"\"\n        categorized = []\n\n        for i in range(0, len(articles), batch_size):\n            batch = articles[i:i+batch_size]\n            print(f\"   Processing batch {i//batch_size + 1}/{(len(articles)-1)//batch_size + 1}...\")\n\n            # Prepare batch for AI\n            headlines_text = \"\\n\".join([\n                f\"{j+1}. [{a['source']}] {a['title']}\"\n                for j, a in enumerate(batch)\n            ])\n\n            prompt = f\"\"\"Categorize these geopolitics/defense headlines into sections for a news aggregator.\n\nSECTIONS (pick ONE per headline):\n- GLOBE: International diplomacy, global institutions, multi-region stories\n- US: United States domestic, Pentagon, Washington policy\n- EUROPE: European nations, NATO, EU, UK, Russia, Ukraine conflict\n- ASIA: China, Taiwan, Japan, Korea, Indo-Pacific, ASEAN, Australia\n- MIDDLE_EAST: Israel, Iran, Gaza, Yemen, Syria, Iraq, Gulf states\n- CONFLICTS: Active warfare, military strikes, battles, combat operations (use this for war/combat stories regardless of region)\n\nPRIORITY:\n- BREAKING: Major developing events, escalations\n- HIGH: Important developments\n- STANDARD: Regular news\n\nHeadlines:\n{headlines_text}\n\nReturn ONLY a JSON array:\n[{{\"index\": 1, \"section\": \"SECTION\", \"priority\": \"PRIORITY\"}}, ...]\"\"\"\n\n            try:\n                response = self.client.messages.create(\n                    model=\"claude-sonnet-4-20250514\",\n                    max_tokens=2000,\n                    messages=[{\"role\": \"user\", \"content\": prompt}]\n                )\n\n                response_text = response.content[0].text.strip()\n                json_match = re.search(r'\\[.*\\]', response_text, re.DOTALL)\n                \n                if json_match:\n                    results = json.loads(json_match.group())\n                    for result in results:\n                        idx = result.get('index', 0) - 1\n                        if 0 <= idx < len(batch):\n                            article = batch[idx].copy()\n                            article['section'] = result.get('section', 'GLOBE')\n                            article['priority'] = result.get('priority', 'STANDARD')\n                            categorized.append(article)\n                else:\n                    for article in batch:\n                        article['section'] = self._guess_section(article['title'])\n                        article['priority'] = self._guess_priority(article['title'])\n                        categorized.append(article)\n\n            except Exception as e:\n                print(f\"   AI error: {e}\")\n                for article in batch:\n                    article['section'] = self._guess_section(article['title'])\n                    article['priority'] = self._guess_priority(article['title'])\n                    categorized.append(article)\n\n            time.sleep(0.3)\n\n        return categorized\n\n    def _guess_section(self, title: str) -> str:\n        \"\"\"Fallback section detection based on keywords.\"\"\"\n        t = title.lower()\n        \n        # Conflicts first (highest priority matching)\n        if any(kw in t for kw in ['strike', 'attack', 'combat', 'battle', 'troops deploy', 'offensive', 'airstrike', 'missile strike', 'killed in', 'war ', 'warfare']):\n            return 'CONFLICTS'\n        \n        # Regional matching\n        if any(kw in t for kw in ['pentagon', 'washington', 'congress', 'u.s.', 'us ', 'american', 'biden', 'trump', 'white house', 'state department']):\n            return 'US'\n        if any(kw in t for kw in ['china', 'taiwan', 'japan', 'korea', 'beijing', 'tokyo', 'pacific', 'indo-pacific', 'asean', 'philippines', 'vietnam', 'australia']):\n            return 'ASIA'\n        if any(kw in t for kw in ['europe', 'nato', 'eu ', 'ukraine', 'russia', 'moscow', 'kyiv', 'britain', 'uk ', 'france', 'germany', 'poland', 'baltic']):\n            return 'EUROPE'\n        if any(kw in t for kw in ['israel', 'iran', 'gaza', 'hamas', 'hezbollah', 'yemen', 'houthi', 'syria', 'iraq', 'saudi', 'gulf', 'lebanon', 'tehran']):\n            return 'MIDDLE_EAST'\n        \n        return 'GLOBE'\n\n    def _guess_priority(self, title: str) -> str:\n        \"\"\"Fallback priority detection.\"\"\"\n        t = title.lower()\n        if any(kw in t for kw in ['breaking', 'urgent', 'just in', 'developing', 'live:']):\n            return 'BREAKING'\n        if any(kw in t for kw in ['attack', 'strike', 'kills', 'dead', 'explosion', 'invasion']):\n            return 'HIGH'\n        return 'STANDARD'\n\n# Initialize if API key is set\nif ANTHROPIC_API_KEY and ANTHROPIC_API_KEY != 'your-anthropic-api-key-here':\n    ai_categorizer = AICategorizor(ANTHROPIC_API_KEY)\n    print(\"AI Categorizer initialized with Claude API\")\nelse:\n    ai_categorizer = AICategorizor(\"dummy\")  # Will use fallback\n    print(\"AI Categorizer using keyword fallback (no API key)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé® Step 6: Website Generator\n",
    "\n",
    "Generates a modern, responsive HTML website with the aggregated news."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "class WebsiteGenerator:\n    \"\"\"Generates Drudge-style dense news aggregation website with IEJ branding.\"\"\"\n\n    def __init__(self, site_title: str, site_subtitle: str, timezone: str):\n        self.site_title = site_title\n        self.site_subtitle = site_subtitle\n        self.tz = pytz.timezone(timezone)\n\n    def generate(self, articles: List[Dict]) -> str:\n        \"\"\"Generate Drudge-style HTML page with IEJ center layout.\"\"\"\n        now = datetime.now(self.tz)\n        timestamp = now.strftime(\"%A, %B %d, %Y %I:%M %p %Z\")\n\n        # Organize articles by section\n        sections = self._organize_by_section(articles)\n        \n        # Get top headline (breaking or highest priority)\n        top_headline = self._get_top_headline(articles)\n\n        html = f'''<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <meta name=\"description\" content=\"{self.site_subtitle}\">\n    <title>{self.site_title} - {self.site_subtitle}</title>\n    <link rel=\"preconnect\" href=\"https://fonts.googleapis.com\">\n    <link href=\"https://fonts.googleapis.com/css2?family=Georgia&family=Arial:wght@400;700&display=swap\" rel=\"stylesheet\">\n    <style>\n        * {{ margin: 0; padding: 0; box-sizing: border-box; }}\n        \n        body {{\n            font-family: Arial, Helvetica, sans-serif;\n            font-size: 14px;\n            line-height: 1.3;\n            background: #ffffff;\n            color: #000000;\n            max-width: 1200px;\n            margin: 0 auto;\n            padding: 10px;\n        }}\n\n        /* Header with IEJ branding */\n        .header {{\n            text-align: center;\n            padding: 15px 0;\n            border-bottom: 3px double #000;\n            margin-bottom: 15px;\n        }}\n\n        .logo {{\n            font-size: 72px;\n            font-weight: bold;\n            font-family: Georgia, serif;\n            letter-spacing: 8px;\n            color: #000;\n            text-shadow: 2px 2px 0 #ccc;\n        }}\n\n        .tagline {{\n            font-size: 11px;\n            color: #666;\n            text-transform: uppercase;\n            letter-spacing: 3px;\n            margin-top: 5px;\n        }}\n\n        .timestamp {{\n            font-size: 11px;\n            color: #333;\n            margin-top: 8px;\n        }}\n\n        /* Top headline banner */\n        .top-headline {{\n            text-align: center;\n            padding: 20px 10px;\n            background: #f5f5f5;\n            border: 1px solid #ddd;\n            margin-bottom: 15px;\n        }}\n\n        .top-headline a {{\n            font-size: 28px;\n            font-weight: bold;\n            color: #cc0000;\n            text-decoration: none;\n            text-transform: uppercase;\n            line-height: 1.2;\n        }}\n\n        .top-headline a:hover {{\n            text-decoration: underline;\n        }}\n\n        .top-headline .source {{\n            font-size: 10px;\n            color: #666;\n            margin-top: 8px;\n            text-transform: uppercase;\n        }}\n\n        /* Main grid - 3 columns with IEJ in center */\n        .main-grid {{\n            display: grid;\n            grid-template-columns: 1fr 1fr 1fr;\n            gap: 0;\n            border: 1px solid #ccc;\n        }}\n\n        /* Section styling */\n        .section {{\n            border-right: 1px solid #ccc;\n            border-bottom: 1px solid #ccc;\n            padding: 0;\n        }}\n\n        .section:nth-child(3n) {{\n            border-right: none;\n        }}\n\n        .section-header {{\n            background: #000;\n            color: #fff;\n            padding: 6px 10px;\n            font-size: 12px;\n            font-weight: bold;\n            text-transform: uppercase;\n            letter-spacing: 1px;\n            text-align: center;\n        }}\n\n        .section-header.globe {{ background: #1a5276; }}\n        .section-header.us {{ background: #1e8449; }}\n        .section-header.europe {{ background: #7d3c98; }}\n        .section-header.asia {{ background: #d35400; }}\n        .section-header.middle-east {{ background: #c0392b; }}\n        .section-header.conflicts {{ background: #000; }}\n\n        /* Center IEJ cell */\n        .center-logo {{\n            display: flex;\n            flex-direction: column;\n            align-items: center;\n            justify-content: center;\n            background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%);\n            padding: 20px;\n            min-height: 200px;\n        }}\n\n        .center-logo .iej {{\n            font-size: 48px;\n            font-weight: bold;\n            font-family: Georgia, serif;\n            color: #fff;\n            letter-spacing: 6px;\n            text-shadow: 2px 2px 4px rgba(0,0,0,0.5);\n        }}\n\n        .center-logo .subtitle {{\n            font-size: 9px;\n            color: #aaa;\n            text-transform: uppercase;\n            letter-spacing: 2px;\n            margin-top: 10px;\n        }}\n\n        /* Headlines list - DENSE like Drudge */\n        .headlines {{\n            padding: 8px;\n            min-height: 180px;\n        }}\n\n        .headline {{\n            margin-bottom: 6px;\n            padding-bottom: 6px;\n            border-bottom: 1px dotted #ddd;\n        }}\n\n        .headline:last-child {{\n            border-bottom: none;\n            margin-bottom: 0;\n            padding-bottom: 0;\n        }}\n\n        .headline a {{\n            color: #0000cc;\n            text-decoration: none;\n            font-size: 13px;\n            line-height: 1.25;\n            display: block;\n        }}\n\n        .headline a:hover {{\n            color: #cc0000;\n            text-decoration: underline;\n        }}\n\n        .headline.breaking a {{\n            color: #cc0000;\n            font-weight: bold;\n        }}\n\n        .headline.high a {{\n            color: #cc6600;\n        }}\n\n        .headline .src {{\n            font-size: 9px;\n            color: #888;\n            text-transform: uppercase;\n            margin-top: 2px;\n        }}\n\n        /* Footer */\n        .footer {{\n            text-align: center;\n            padding: 15px;\n            margin-top: 15px;\n            border-top: 3px double #000;\n            font-size: 10px;\n            color: #666;\n        }}\n\n        /* Responsive */\n        @media (max-width: 800px) {{\n            .main-grid {{\n                grid-template-columns: 1fr;\n            }}\n            .section {{\n                border-right: none;\n            }}\n            .logo {{ font-size: 48px; }}\n            .top-headline a {{ font-size: 20px; }}\n        }}\n\n        /* Print styles */\n        @media print {{\n            body {{ font-size: 10px; }}\n            .top-headline {{ background: none; }}\n        }}\n    </style>\n</head>\n<body>\n    <header class=\"header\">\n        <div class=\"logo\">IEJ</div>\n        <div class=\"tagline\">{self.site_subtitle}</div>\n        <div class=\"timestamp\">{timestamp}</div>\n    </header>\n\n    {self._generate_top_headline(top_headline)}\n\n    <div class=\"main-grid\">\n        <!-- Row 1: Globe | US | Europe -->\n        {self._generate_section('GLOBE', 'globe', sections.get('GLOBE', []))}\n        {self._generate_section('US', 'us', sections.get('US', []))}\n        {self._generate_section('EUROPE', 'europe', sections.get('EUROPE', []))}\n        \n        <!-- Row 2: Asia | IEJ Center | Middle East -->\n        {self._generate_section('ASIA', 'asia', sections.get('ASIA', []))}\n        \n        <div class=\"section\">\n            <div class=\"center-logo\">\n                <div class=\"iej\">IEJ</div>\n                <div class=\"subtitle\">Intelligence Brief</div>\n            </div>\n        </div>\n        \n        {self._generate_section('MIDDLE EAST', 'middle-east', sections.get('MIDDLE_EAST', []))}\n        \n        <!-- Row 3: Conflicts spans or additional -->\n        {self._generate_section('CONFLICTS', 'conflicts', sections.get('CONFLICTS', []))}\n    </div>\n\n    <footer class=\"footer\">\n        AI-Powered Intelligence Aggregation | Headlines from {len(set(a.get('source', '') for a in articles))} sources | Updated {now.strftime('%I:%M %p')}\n    </footer>\n</body>\n</html>'''\n\n        return html\n\n    def _organize_by_section(self, articles: List[Dict]) -> Dict:\n        \"\"\"Organize articles by section.\"\"\"\n        sections = {s: [] for s in ['GLOBE', 'US', 'EUROPE', 'ASIA', 'MIDDLE_EAST', 'CONFLICTS']}\n        \n        # Sort by priority first\n        priority_order = {'BREAKING': 0, 'HIGH': 1, 'STANDARD': 2}\n        sorted_articles = sorted(\n            articles,\n            key=lambda x: (\n                priority_order.get(x.get('priority', 'STANDARD'), 2),\n                -(x.get('published') or datetime.min.replace(tzinfo=pytz.UTC)).timestamp()\n            )\n        )\n        \n        for article in sorted_articles:\n            section = article.get('section', 'GLOBE')\n            if section in sections and len(sections[section]) < HEADLINES_PER_SECTION:\n                sections[section].append(article)\n        \n        return sections\n\n    def _get_top_headline(self, articles: List[Dict]) -> Optional[Dict]:\n        \"\"\"Get the most important headline for the banner.\"\"\"\n        breaking = [a for a in articles if a.get('priority') == 'BREAKING']\n        if breaking:\n            return breaking[0]\n        high = [a for a in articles if a.get('priority') == 'HIGH']\n        if high:\n            return high[0]\n        return articles[0] if articles else None\n\n    def _generate_top_headline(self, article: Optional[Dict]) -> str:\n        \"\"\"Generate the top headline banner.\"\"\"\n        if not article:\n            return ''\n        return f'''\n    <div class=\"top-headline\">\n        <a href=\"{article.get('url', '#')}\" target=\"_blank\">{article.get('title', '').upper()}</a>\n        <div class=\"source\">{article.get('source', '')}</div>\n    </div>'''\n\n    def _generate_section(self, title: str, css_class: str, articles: List[Dict]) -> str:\n        \"\"\"Generate a section with headlines.\"\"\"\n        headlines_html = ''\n        for article in articles:\n            priority_class = ''\n            if article.get('priority') == 'BREAKING':\n                priority_class = 'breaking'\n            elif article.get('priority') == 'HIGH':\n                priority_class = 'high'\n            \n            headlines_html += f'''\n            <div class=\"headline {priority_class}\">\n                <a href=\"{article.get('url', '#')}\" target=\"_blank\">{article.get('title', 'Untitled')}</a>\n                <div class=\"src\">{article.get('source', '')}</div>\n            </div>'''\n        \n        if not headlines_html:\n            headlines_html = '<div class=\"headline\"><span style=\"color:#999\">No headlines</span></div>'\n        \n        return f'''\n        <div class=\"section\">\n            <div class=\"section-header {css_class}\">{title}</div>\n            <div class=\"headlines\">{headlines_html}</div>\n        </div>'''\n\n# Initialize generator\ngenerator = WebsiteGenerator(SITE_TITLE, SITE_SUBTITLE, TIMEZONE)\nprint(\"Website Generator initialized - Drudge-style layout\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Step 7: GitHub Pages Deployment\n",
    "\n",
    "Automatically deploy the generated website to GitHub Pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from github import Github\n",
    "import base64\n",
    "\n",
    "class GitHubDeployer:\n",
    "    \"\"\"Deploy generated website to GitHub Pages.\"\"\"\n",
    "\n",
    "    def __init__(self, token: str, repo_name: str, branch: str = \"gh-pages\"):\n",
    "        self.github = Github(token)\n",
    "        self.repo = self.github.get_repo(repo_name)\n",
    "        self.branch = branch\n",
    "\n",
    "    def deploy(self, html_content: str, filename: str = \"index.html\") -> str:\n",
    "        \"\"\"Deploy HTML file to GitHub Pages.\"\"\"\n",
    "        try:\n",
    "            # Check if branch exists\n",
    "            try:\n",
    "                self.repo.get_branch(self.branch)\n",
    "            except:\n",
    "                # Create branch from main/master\n",
    "                default_branch = self.repo.default_branch\n",
    "                source = self.repo.get_branch(default_branch)\n",
    "                self.repo.create_git_ref(\n",
    "                    ref=f\"refs/heads/{self.branch}\",\n",
    "                    sha=source.commit.sha\n",
    "                )\n",
    "                print(f\"   Created branch: {self.branch}\")\n",
    "\n",
    "            # Check if file exists\n",
    "            try:\n",
    "                file = self.repo.get_contents(filename, ref=self.branch)\n",
    "                # Update existing file\n",
    "                self.repo.update_file(\n",
    "                    path=filename,\n",
    "                    message=f\"Update {filename} - {datetime.now().strftime('%Y-%m-%d %H:%M')}\",\n",
    "                    content=html_content,\n",
    "                    sha=file.sha,\n",
    "                    branch=self.branch\n",
    "                )\n",
    "                print(f\"   ‚úì Updated {filename}\")\n",
    "            except:\n",
    "                # Create new file\n",
    "                self.repo.create_file(\n",
    "                    path=filename,\n",
    "                    message=f\"Create {filename} - {datetime.now().strftime('%Y-%m-%d %H:%M')}\",\n",
    "                    content=html_content,\n",
    "                    branch=self.branch\n",
    "                )\n",
    "                print(f\"   ‚úì Created {filename}\")\n",
    "\n",
    "            # Return the GitHub Pages URL\n",
    "            owner = self.repo.owner.login\n",
    "            repo_name = self.repo.name\n",
    "            return f\"https://{owner}.github.io/{repo_name}/\"\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö†Ô∏è Deploy error: {e}\")\n",
    "            return None\n",
    "\n",
    "# Initialize deployer if token is available\n",
    "if GITHUB_TOKEN:\n",
    "    deployer = GitHubDeployer(GITHUB_TOKEN, GITHUB_REPO, GITHUB_BRANCH)\n",
    "    print(\"‚úÖ GitHub Deployer initialized\")\n",
    "else:\n",
    "    deployer = None\n",
    "    print(\"‚ö†Ô∏è GitHub Deployer not initialized - will save locally only\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ñ∂Ô∏è Step 8: Run the Aggregator\n",
    "\n",
    "Execute the complete pipeline: Fetch ‚Üí Categorize ‚Üí Generate ‚Üí Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def run_aggregator(deploy: bool = True, save_local: bool = True):\n    \"\"\"\n    Run the complete news aggregation pipeline.\n\n    Args:\n        deploy: Whether to deploy to GitHub Pages\n        save_local: Whether to save HTML file locally\n    \"\"\"\n    print(\"=\"*60)\n    print(\"IEJ GEOPOLITICS NEWS AGGREGATOR\")\n    print(f\"Started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n    print(\"=\"*60)\n\n    # Step 1: Fetch news\n    print(\"\\n[1/4] Fetching News...\")\n    articles = fetcher.fetch_all()\n\n    if not articles:\n        print(\"\\nNo articles fetched. Check your internet connection.\")\n        return None, None\n\n    # Step 2: AI Categorization\n    print(\"\\n[2/4] Categorizing Headlines...\")\n    if ANTHROPIC_API_KEY and ANTHROPIC_API_KEY != 'your-anthropic-api-key-here':\n        categorized = ai_categorizer.categorize_batch(articles)\n    else:\n        print(\"   Using keyword-based categorization...\")\n        categorized = []\n        for article in articles:\n            article['section'] = ai_categorizer._guess_section(article['title'])\n            article['priority'] = ai_categorizer._guess_priority(article['title'])\n            categorized.append(article)\n\n    # Print summary\n    print(\"\\nCategorization Summary:\")\n    sections_count = {}\n    for a in categorized:\n        s = a.get('section', 'GLOBE')\n        sections_count[s] = sections_count.get(s, 0) + 1\n    \n    for section, count in sorted(sections_count.items()):\n        print(f\"   {section}: {count}\")\n\n    # Step 3: Generate HTML\n    print(\"\\n[3/4] Generating Website...\")\n    html = generator.generate(categorized)\n    print(f\"   Generated {len(html):,} bytes\")\n\n    # Step 4: Save locally\n    if save_local:\n        with open(OUTPUT_FILENAME, 'w', encoding='utf-8') as f:\n            f.write(html)\n        print(f\"   Saved to: {OUTPUT_FILENAME}\")\n\n    # Step 5: Deploy to GitHub Pages\n    if deploy and deployer:\n        print(\"\\n[4/4] Deploying to GitHub Pages...\")\n        url = deployer.deploy(html, OUTPUT_FILENAME)\n        if url:\n            print(f\"\\nDEPLOYMENT SUCCESSFUL!\")\n            print(f\"Live at: {url}\")\n    else:\n        print(\"\\n[4/4] Skipping deployment (no token)\")\n\n    print(\"\\n\" + \"=\"*60)\n    print(f\"COMPLETE - {len(categorized)} headlines aggregated\")\n    print(\"=\"*60)\n\n    return html, categorized\n\n# Run the aggregator\nhtml_output, articles_data = run_aggregator(deploy=False, save_local=True)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üëÄ Step 9: Preview the Website\n",
    "\n",
    "Display the generated website directly in Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "\n",
    "# Display in an iframe\n",
    "if html_output:\n",
    "    display(HTML(f'''\n",
    "    <div style=\"border: 1px solid #333; border-radius: 8px; overflow: hidden; margin: 20px 0;\">\n",
    "        <iframe srcdoc=\"{html_output.replace('\"', '&quot;')}\" \n",
    "                style=\"width: 100%; height: 800px; border: none;\"\n",
    "                sandbox=\"allow-same-origin allow-scripts allow-popups allow-forms\">\n",
    "        </iframe>\n",
    "    </div>\n",
    "    '''))\n",
    "    print(\"üëÜ Preview above. Scroll to explore all sections.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚è∞ Step 10: Schedule Automatic Updates (Optional)\n",
    "\n",
    "Set up automatic updates using Colab's scheduling or external services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def scheduled_run(interval_minutes: int = 60, max_runs: int = 24):\n",
    "    \"\"\"\n",
    "    Run the aggregator on a schedule.\n",
    "\n",
    "    Args:\n",
    "        interval_minutes: Time between updates\n",
    "        max_runs: Maximum number of runs before stopping\n",
    "    \"\"\"\n",
    "    print(f\"üïê Starting scheduled runs every {interval_minutes} minutes\")\n",
    "    print(f\"   Max runs: {max_runs}\")\n",
    "    print(f\"   Press Runtime > Interrupt to stop\\n\")\n",
    "\n",
    "    for i in range(max_runs):\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"RUN {i+1}/{max_runs}\")\n",
    "        print(f\"{'='*50}\")\n",
    "\n",
    "        try:\n",
    "            run_aggregator(deploy=True, save_local=True)\n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚ùå Error in run {i+1}: {e}\")\n",
    "\n",
    "        if i < max_runs - 1:\n",
    "            next_run = datetime.now() + timedelta(minutes=interval_minutes)\n",
    "            print(f\"\\n‚è∞ Next run at: {next_run.strftime('%H:%M:%S')}\")\n",
    "            time.sleep(interval_minutes * 60)\n",
    "\n",
    "    print(\"\\n‚úÖ Scheduled runs complete!\")\n",
    "\n",
    "# Uncomment to run on schedule:\n",
    "# scheduled_run(interval_minutes=60, max_runs=24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì• Step 11: Download the HTML File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import files\n",
    "    files.download(OUTPUT_FILENAME)\n",
    "    print(f\"‚úÖ Downloaded: {OUTPUT_FILENAME}\")\n",
    "except:\n",
    "    print(f\"üìÅ File saved locally: {OUTPUT_FILENAME}\")\n",
    "    print(\"   (Download manually if not in Colab)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìñ Usage Guide\n",
    "\n",
    "### Quick Start\n",
    "1. Set your `ANTHROPIC_API_KEY` in Colab secrets\n",
    "2. Run all cells (Runtime > Run all)\n",
    "3. Preview your site in Step 9\n",
    "4. Download in Step 11\n",
    "\n",
    "### GitHub Pages Deployment\n",
    "1. Create a GitHub Personal Access Token with `repo` scope\n",
    "2. Add as `GITHUB_TOKEN` in Colab secrets\n",
    "3. Update `GITHUB_REPO` with your repository\n",
    "4. Enable GitHub Pages in repo settings (source: `gh-pages` branch)\n",
    "\n",
    "### Customization\n",
    "- Edit `NEWS_SOURCES` to add/remove news sources\n",
    "- Modify `WebsiteGenerator` CSS for different themes\n",
    "- Adjust `PRIORITY_KEYWORDS` for different focus areas\n",
    "\n",
    "### Tips\n",
    "- Without an Anthropic API key, the system uses keyword-based categorization (less accurate)\n",
    "- Run during off-peak hours for faster RSS fetching\n",
    "- Use scheduled runs for continuous updates\n",
    "\n",
    "---\n",
    "\n",
    "*Built with ‚ù§Ô∏è for geopolitics enthusiasts*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}